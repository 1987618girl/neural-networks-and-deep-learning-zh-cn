# 改进神经网络的学习方法

当一个高尔夫球员刚开始学习打高尔夫时，他们通常会在挥杆的练习上花费大多数时间。慢慢地他们才会在基本的挥杆上通过变化发展其他的击球方式，学习低飞球、左曲球和右曲球。类似的，我们现在仍然聚焦在反向传播算法的理解上。这就是我们的“基本挥杆”——神经网络中大部分工作学习和研究的基础。本章，我会解释若干技术能够用来提升我们关于反向传播的初级的实现，最终改进网络学习的方式。

本章涉及的技术包括：更好的代价函数的选择——[交叉熵](http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function) 代价函数；四中规范化方法（L1 和 L2 规范化，dropout 和训练数据的人工扩展），这会让我们的网络在训练集之外的数据上更好地泛化；更好的[权重初始化方法](http://neuralnetworksanddeeplearning.com/chap3.html#weight_initialization)；还有[帮助选择好的超参数的启发式想法](http://neuralnetworksanddeeplearning.com/chap3.html#how_to_choose_a_neural_network's_hyper-parameters)。同样我也会再给出一些简要的[其他技术介绍](http://neuralnetworksanddeeplearning.com/chap3.html#other_techniques)。这些讨论之间的独立性比较大，所有你们可以随自己的意愿挑着看。另外我还会在代码中实现这些技术，使用他们来提高在第一章中的分类问题上的性能。

当然，我们仅仅覆盖了大量已经在神经网络中研究发展出的技术的一点点内容。此处我们学习深度学习的观点是想要在一些已有的技术上入门的最佳策略其实是深入研究一小部分最重要那些的技术点。掌握了这些关键技术不仅仅对这些技术本身的理解很有用，而且会深化你对使用神经网络时会遇到哪些问题的理解。这会让你们做好在需要时快速掌握其他技术的充分准备。

## 交叉熵代价函数
---
我们大多数人觉得错了就很不爽。在开始学习弹奏钢琴不久后，我在一个听众前做了处女秀。我很紧张，开始时将八度音阶的曲段演奏得很低。我很困惑，因为不能继续演奏下去了，直到有个人指出了其中的错误。当时，我非常尴尬。不过，尽管不开心，我们却能够因为明显的犯错快速地学习到正确的东西。你应该相信下次我再演奏肯定会是正确的！相反，在我们的错误不是很好的定义的时候，学习的过程会变得更加缓慢。

理想地，我们希望和期待神经网络可以从错误中快速地学习。在实践中，这种情况经常出现么？为了回答这个问题，让我们看看一个小例子。这个例子包含一个只有一个输入的神经元：

![](http://upload-images.jianshu.io/upload_images/42741-54bcf1d440d6de82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们会训练这个神经元来做一件非常简单的事：让输入 $$1$$ 转化为 $$0$$。当然，这很简单了，手工找到合适的权重和偏差就可以了，不需要什么学习算法。然而，看起来使用梯度下降的方式来学习权重和偏差是很有启发的。所以，我们来看看神经元如何学习。

为了让事情确定化，我会首先将权重和偏差初始化为 $$0.6$$ 和 $$0.9$$。这些就是一般的开始学习的选择，并没有任何刻意的想法。一开始的神经元的输出是 $$0.82$$，所以这离我们的目标输出 $$0.0$$ 还差得很远。点击右下角的“运行”按钮来看看神经元如何学习到让输出接近 $$0.0$$ 的。注意到，这并不是一个已经录好的动画，你的浏览器实际上是正在进行梯度的计算，然后使用梯度更新来对权重和偏差进行更新，并且展示结果。设置学习率  $$\eta=0.15$$ 进行学习一方面足够慢的让我们跟随学习的过程，另一方面也保证了学习的时间不会太久，几秒钟应该就足够了。代价函数是我们前面用到的二次函数，$$C$$。这里我也会给出准确的形式，所以不需要翻到前面查看定义了。注意，你可以通过点击 “Run” 按钮执行训练若干次。

![1](http://upload-images.jianshu.io/upload_images/42741-752fcc2176bf9b8c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![2](http://upload-images.jianshu.io/upload_images/42741-99457432d0a54542.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![3](http://upload-images.jianshu.io/upload_images/42741-1eedcdca670ee566.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![4](http://upload-images.jianshu.io/upload_images/42741-b2e1647ff9c88555.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 我们这里是静态的例子，在原书中，使用的动态示例，所以为了更好的效果，请参考[原书的此处动态示例](http://neuralnetworksanddeeplearning.com/chap3.html)。

正如你所见，神经元快速地学到了使得代价函数下降的权重和偏差，给出了最终的输出为 $$0.09$$。这虽然不是我们的目标输出 $$0.0$$，但是已经挺好了。假设我们现在将初始权重和偏差都设置为 $$2.0$$。此时初始输出为 $$0.98$$，这是和目标值的差距相当大的。现在看看神经元学习的过程。点击“Run” 按钮：

![1](http://upload-images.jianshu.io/upload_images/42741-95ceb66b3451dbb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![2](http://upload-images.jianshu.io/upload_images/42741-68d123092f32aed6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![3](http://upload-images.jianshu.io/upload_images/42741-bff381a28137c4b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![4](http://upload-images.jianshu.io/upload_images/42741-83d1aa344e862ab9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![5](http://upload-images.jianshu.io/upload_images/42741-d16017b9a247c13f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

虽然这个例子使用的了同样的学习率（$$\eta=0.15$$），我们可以看到刚开始的学习速度是比较缓慢的。对前 $$150$$ 左右的学习次数，权重和偏差并没有发生太大的变化。随后学习速度加快，与上一个例子中类似了，神经网络的输出也迅速接近 $$0.0$$。

> 强烈建议参考[原书的此处动态示例](http://neuralnetworksanddeeplearning.com/chap3.html)感受学习过程的差异。

这种行为看起来和人类学习行为差异很大。正如我在此节开头所说，我们通常是在犯错比较明显的时候学习的速度最快。但是我们已经看到了人工神经元在其犯错较大的情况下其实学习很有难度。而且，这种现象不仅仅是在这个小例子中出现，也会再更加一般的神经网络中出现。为何学习如此缓慢？我们能够找到缓解这种情况的方法么？

为了理解这个问题的源头，想想神经元是按照偏导数（$$\partial C/\partial w$$ 和 $$\partial C/\partial b$$）和学习率（$$\eta$$）的乘积来改变权重和偏差的。所以，我们在说“学习缓慢”时，实际上就是说这些偏导数很小。理解他们为何这么小就是我们面临的挑战。为了理解这些，让我们计算偏导数看看。我们一直在用的是二次代价函数，定义如下

![](http://upload-images.jianshu.io/upload_images/42741-689311744b65e8ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$a$$ 是神经元的输出，其中训练输入为 $$x=1$$，$$y=0$$ 则是目标输出。显式地使用权重和偏差来表达这个，我们有 $$a=\sigma(z)$$，其中 $$z=wx+b$$。使用链式法则来求偏导数就有：

![](http://upload-images.jianshu.io/upload_images/42741-fa97259e24bc11d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中我已经将 $$x=1$$ 和 $$y=0$$ 代入了。为了理解这些表达式的行为，让我们仔细看 $$\sigma'(z)$$ 这一项。首先回忆一下 $$\sigma$$ 函数图像：

![](http://upload-images.jianshu.io/upload_images/42741-8ff397e1f73e4090.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以从这幅图看出，当神经元的输出接近 $$1$$ 的时候，曲线变得相当平，所以 $$\sigma'(z)$$ 就很小了。方程 (55) 和 (56) 也告诉我们 $$\partial C/\partial w$$ 和 $$\partial C/\partial b$$ 会非常小。这其实就是学习缓慢的原因所在。而且，我们后面也会提到，这种学习速度下降的原因实际上也是更加一般的神经网络学习缓慢的原因，并不仅仅是在这个特例中特有的。

### 引入交叉熵代价函数
那么我们如何解决这个问题呢？研究表明，我们可以通过使用交叉熵代价函数来替换二次代价函数。为了理解什么是交叉熵，我们稍微改变一下之前的简单例子。假设，我们现在要训练一个包含若干输入变量的的神经元，$$x_1,x_2,...$$ 对应的权重为 $$w_1,w_2,...$$ 和偏差，$$b$$：

![](http://upload-images.jianshu.io/upload_images/42741-9f1c9f7efd4815ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

神经元的输出就是 $$a=\sigma(z)$$，其中 $$z=\sum_jw_jx_j+b$$ 是输入的带权和。我们如下定义交叉熵代价函数：

![](http://upload-images.jianshu.io/upload_images/42741-f3363ceff9e87fb4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$n$$ 是训练数据的总数，对所有的训练数据 $$x$$ 和 对应的目标输出 $$y$$ 进行求和。

公式(57)是否解决学习缓慢的问题并不明显。实际上，甚至将这个定义看做是代价函数也不是显而易见的！在解决学习缓慢前，我们来看看交叉熵为何能够解释成一个代价函数。

将交叉熵看做是代价函数有两点原因。第一，它使非负的，$$C>0$$。可以看出：(a) 公式(57)的和式中所有独立的项都是非负的，因为对数函数的定义域是 $$(0,1)$$；(b) 前面有一个负号。

第二，如果神经元实际的输出接近目标值。假设在这个例子中，$$y=0$$ 而 $$a\approx 0$$。这是我们想到得到的结果。我们看到公式(57)中第一个项就消去了，因为 $$y=0$$，而第二项实际上就是 $$-\ln (1-a)\approx 0$$。反之，$$y=1$$ 而 $$a\approx 1$$。所以在实际输出和目标输出之间的差距越小，最终的交叉熵的值就越低了。

综上所述，交叉熵是非负的，在神经元达到很好的正确率的时候会接近 $$0$$。这些其实就是我们想要的代价函数的特性。其实这些特性也是二次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有一个比二次代价函数更好的特性就是它避免了学习速度下降的问题。为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将 $$a=\sigma(z)$$ 代入到公式 (57) 中应用两次链式法则，得到：

![](http://upload-images.jianshu.io/upload_images/42741-f5e7c6fea8b38d47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

将结果合并一下，简化成：

![](http://upload-images.jianshu.io/upload_images/42741-38fcdc9659b6b608.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

根据 $$\sigma(z) = 1/(1+e^{-z})$$ 的定义，和一些运算，我们可以得到 $$\sigma'(z) = \sigma(z)(1-\sigma(z))$$。后面在练习中会要求你计算这个，现在可以直接使用这个结果。我们看到 $$\sigma'$$ 和 $$\sigma(z)(1-\sigma(z))$$ 这两项在方程中直接约去了，所以最终形式就是：

![](http://upload-images.jianshu.io/upload_images/42741-5575d9699b92480b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这是一个优美的公式。它告诉我们权重学习的速度受到 $$\sigma(z)-y$$，也就是输出中的误差的控制。更大的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在二次代价函数中类似公式中 $$\sigma'(z)$$ 导致的学习缓慢，见公式(55)。当我们使用交叉熵的时候，$$\sigma'(z)$$ 被约掉了，所以我们不再需要关心它是不是变得很小。这种约除就是交叉熵带来的特效。实际上，这也并不是非常奇迹的事情。我们在后面可以看到，交叉熵其实只是满足这种特性的一种选择罢了。

根据类似的方法，我们可以计算出关于偏差的偏导数。我这里不再给出详细的过程，你可以轻易验证得到

![](http://upload-images.jianshu.io/upload_images/42741-05567745404c5dcd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 练习
* 验证 $$\sigma'(z) = \sigma(z)(1-\sigma(z))$$。

让我们重回最原初的例子，来看看换成了交叉熵之后的学习过程。现在仍然按照前面的参数配置来初始化网络，开始权重为 $$0.6$$，而偏差为 $$0.9$$。点击“Run”按钮看看在换成交叉熵之后网络的学习情况：

![1](http://upload-images.jianshu.io/upload_images/42741-236a80d9625b7533.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![2](http://upload-images.jianshu.io/upload_images/42741-d94d7466e960b38c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![3](http://upload-images.jianshu.io/upload_images/42741-d8971200e55bc88b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![4](http://upload-images.jianshu.io/upload_images/42741-cfa4b9cf7de3b2c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![5](http://upload-images.jianshu.io/upload_images/42741-9aadf7001094c81d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

毫不奇怪，在这个例子中，神经元学习得相当出色，跟之前差不多。现在我们再看看之前出问题的那个例子，权重和偏差都初始化为 $$2.0$$：

![1](http://upload-images.jianshu.io/upload_images/42741-461c7ebcebdc9551.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![2](http://upload-images.jianshu.io/upload_images/42741-bd5ac4ae285ff597.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![3](http://upload-images.jianshu.io/upload_images/42741-24b6e22490e6469e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![4](http://upload-images.jianshu.io/upload_images/42741-4fedc8ddbdb3a5cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![5](http://upload-images.jianshu.io/upload_images/42741-0860b6265dfa1305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

成功了！这次神经元的学习速度相当快，跟我们预期的那样。如果你观测的足够仔细，你可以发现代价函数曲线要比二次代价函数训练前面部分要陡很多。正是交叉熵带来的快速下降的坡度让神经元在处于误差很大的情况下能够逃脱出学习缓慢的困境，这才是我们直觉上所期待的效果。

我们还没有提及关于学习率的讨论。刚开始使用二次代价函数的时候，我们使用了 $$\eta=0.15$$。在新例子中，我们还应该使用同样的学习率么？实际上，根据不同的代价函数，我们不能够直接去套用同样的学习率。这好比苹果和橙子的比较。对于这两种代价函数，我只是通过简单的实验来找到一个能够让我们看清楚变化过程的学习率的值。尽管我不愿意提及，但如果你仍然好奇，这个例子中我使用了 $$\eta=0.005$$。

你可能会反对说，上面学习率的改变使得上面的图失去了意义。谁会在意当学习率的选择是任意挑选的时候神经元学习的速度？！这样的反对其实没有抓住重点。上面的图例不是想讨论学习的绝对速度。而是想研究学习速度的变化情况。特别地，当我们使用二次代价函数时，学习在神经元犯了明显的错误的时候却比学习快接近真实值的时候缓慢；而使用交叉熵学习正是在神经元犯了明显错误的时候速度更快。这些现象并不是因为学习率的改变造成的。

我们已经研究了一个神经元的交叉熵。不过，将其推广到多个神经元的多层神经网络上也是很简单的。特别地，假设 $$y=y_1,y_2,...$$ 是输出神经元上的目标值，而 $$a_1^L,a_2^L,...$$是实际输出值。那么我们定义交叉熵如下

![](http://upload-images.jianshu.io/upload_images/42741-80db42bf50ee6cfa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

除了这里需要对所有输出神经元进行求和外，这个其实和我们早前的公式(57)一样的。这里不会给出一个推算的过程，但需要说明的时使用公式(63)确实会在很多的神经网络中避免学习的缓慢。如果你感兴趣，你可以尝试一下下面问题的推导。

那么我们应该在什么时候用交叉熵来替换二次代价函数？实际上，如果在输出神经元使用 sigmoid 激活函数时，交叉熵一般都是更好的选择。为什么？考虑一下我们初始化网络的时候通常使用某种随机方法。可能会发生这样的情况，这些初始选择会对某些训练输入误差相当明显——比如说，目标输出是 $$1$$，而实际值是 $$0$$，或者完全反过来。如果我们使用二次代价函数，那么这就会导致学习速度的下降。它并不会完全终止学习的过程，因为这些权重会持续从其他的样本中进行学习，但是显然这不是我们想要的效果。

### 练习
* 一个小问题就是刚接触交叉熵时，很难一下子记住那些表达式对应的角色。又比如说，表达式的正确形式是 $$−[y\ln a+(1−y)\ln (1−a)]$$
 或者 $$−[a\ln y+(1−a)\ln (1−y)]$$。在 $$y=0$$ 或者 $$1$$ 的时候第二个表达式的结果怎样？这个问题会影响第一个表达式么？为什么？
* 在对单个神经元讨论中，我们指出如果对所有的训练数据有 $$\sigma(z)\approx y$$，交叉熵会很小。这个论断其实是和 $$y$$ 只是等于 $$1$$ 或者 $$0$$ 有关。这在分类问题一般是可行的，但是对其他的问题（如回归问题）$$y$$ 可以取 $$0$$  和 $$1$$ 之间的中间值的。证明，交叉熵在 $$\sigma(z)=y$$ 时仍然是最小化的。此时交叉熵的表示是：

![](http://upload-images.jianshu.io/upload_images/42741-5c38ff3dd38581ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而其中 $$−[y\ln y+(1−y)\ln (1−y)]$$ 有时候被称为 [二元熵](http://en.wikipedia.org/wiki/Binary_entropy_function)

### 问题
* **多层多神经元网络** 用上一章的定义符号，证明对二次代价函数，关于输出层的权重的偏导数为

![](http://upload-images.jianshu.io/upload_images/42741-312d7eff0fb92419.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

项 $$\sigma'(z_j^L)$$ 会在一个输出神经元困在错误值时导致学习速度的下降。证明对于交叉熵代价函数，针对一个训练样本 $$x$$ 的输出误差 $$\delta^L$$为

![](http://upload-images.jianshu.io/upload_images/42741-6cc31b8740f5b9c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用这个表达式来证明关于输出层的权重的偏导数为

![](http://upload-images.jianshu.io/upload_images/42741-adf20b59d623ed79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里 $$\sigma'(z_j^L)$$ 就消失了，所以交叉熵避免了学习缓慢的问题，不仅仅是在一个神经元上，而且在多层多元网络上都起作用。这个分析过程稍作变化对偏差也是一样的。如果你对这个还不确定，那么请仔细研读一下前面的分析。

* **在输出层使用线性神经元时使用二次代价函数** 假设我们有一个多层多神经元网络，最终输出层的神经元都是线性的，输出不再是 sigmoid 函数作用的结果，而是 $$a_j^L = z_j^L$$。证明如果我们使用二次代价函数，那么对单个训练样本 $$x$$ 的输出误差就是

![](http://upload-images.jianshu.io/upload_images/42741-ab87835060e9894f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

类似于前一个问题，使用这个表达式来证明关于输出层的权重和偏差的偏导数为

![](http://upload-images.jianshu.io/upload_images/42741-29173e61d12177c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这表明如果输出神经元是线性的那么二次代价函数不再会导致学习速度下降的问题。在此情形下，二次代价函数就是一种合适的选择。

### 使用交叉熵来对 MNIST 数字进行分类
交叉熵很容易作为使用梯度下降和反向传播方式进行模型学习的一部分来实现。我们将会在下一章进行对前面的程序 `network.py` 的改进。新的程序写在 `network2.py` 中，不仅使用了交叉熵，还有本章中介绍的其他的技术。现在我们看看新的程序在进行 MNIST 数字分类问题上的表现。如在第一章中那样，我们会使用一个包含 $$30$$ 个隐藏元的网络，而 minibatch 的大小也设置为 $$10$$。我们将学习率设置为 $$\eta=0.5$$ 然后训练 $$30$$ 回合。`network2.py` 的接口和 `network.py` 稍微不同，但是过程还是很清楚的。你可以使用如 `help(network2.Network.SGD)` 这样的命令来检查对应的文档。
```python
>>> import mnist_loader
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
>>> import network2
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)
>>> net.large_weight_initializer()
>>> net.SGD(training_data, 30, 10, 0.5, evaluation_data=test_data,
... monitor_evaluation_accuracy=True)
```

注意看下，`net.large_weight_initializer()` 命令使用和第一章介绍的同样的方式来进行权重和偏差的初始化。运行上面的代码我们得到了一个 95.49% 准确度的网络。这跟我们在第一章中使用二次代价函数得到的结果相当接近了，95.42%。

同样也来试试使用 $$100$$ 个隐藏元的交叉熵及其他参数保持不变的情况。在这个情形下，我们获得了 96.82% 的准确度。相比第一章使用二次代价函数的结果 96.59%，这有一定的提升。这看起来是一个小小的变化，但是考虑到误差率已经从 3.41% 下降到 3.18%了。我们已经消除了原误差的 $$1/14$$。这其实是可观的改进。

令人振奋的是交叉熵代价函数给了我们类似的或者更好的结果。然而，这些结果并没有能够确定性地证明交叉熵是更好的选择。原因在于我已经在选择诸如学习率，minibatch 大小等等这样的超参数上做出了一些努力。为了让这些提升更具说服力，我们需要进行对超参数进行深度的优化。当然，这些结果都挺好的，强化了我们早先关于交叉熵优于二次代价的理论论断。

这只是本章后面的内容和整本书剩余内容中的更为一般的模式的一部分。我们将给出一个新的技术，然后进行尝试，随后获得“提升的”结果。当然，看到这些进步是很好的。但是这些提升的解释一般来说都困难重重。在进行了大量工作来优化所有其他的超参数，使得提升真的具有说服力。工作量很大，需要大量的计算能力，我们也不会进行这样耗费的调查。相反，我采用上面进行的那些不正式的测试来达成目标。所以你要记住这样的测试缺少确定性的证明，需要注意那些使得论断失效的信号。

至此，我们已经花了大量篇幅介绍交叉熵。为何对一个只能给出一点点性能提升的技术上花费这么多的精力？后面，我们会看到其他的技术——规范化，会带来更大的提升效果。所以为何要这么细致地讨论交叉熵？部分原因在于交叉熵是一种广泛使用的代价函数，值得深入理解。但是更加重要的原因是神经元的饱和是神经网络中一个关键的问题，整本书都会不断回归到这个问题上。因此我现在深入讨论交叉熵就是因为这是一种开始理解神经元饱和和如何解决这个问题的很好的实验。

### 交叉熵的含义？源自哪里？
我们对于交叉熵的讨论聚焦在代数分析和代码实现。这虽然很有用，但是也留下了一个未能回答的更加宽泛的概念上的问题，如：交叉熵究竟表示什么？存在一些直觉上的思考交叉熵的方法么？我们如何想到这个概念？

让我们从最后一个问题开始回答：什么能够激发我们想到交叉熵？假设我们发现学习速度下降了，并理解其原因是因为在公式(55)(56)中的 $$\sigma'(z)$$ 那一项。在研究了这些公式后，我们可能就会想到选择一个不包含 $$\sigma'(z)$$ 的代价函数。所以，这时候对一个训练样本 $$x$$，代价函数是 $$C=C_x$$ 就满足：

![](http://upload-images.jianshu.io/upload_images/42741-373b9b6f27c9c74f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如果我们选择的代价函数满足这些条件，那么同样他们会拥有遇到明显误差时的学习速度越快这样的特性。这也能够解决学习速度下降的问题。实际上，从这些公式开始，现在就给你们看看若是跟随自身的数学嗅觉推导出交叉熵的形式是可能的。我们来推一下，由链式法则，我们有

![](http://upload-images.jianshu.io/upload_images/42741-5f58cf963a71bce6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用 $$\sigma'(z)=\sigma(z)(1-\sigma(z))=a(1-a)$$，上个等式就变成

![](http://upload-images.jianshu.io/upload_images/42741-2564f711fb4365d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对比等式(72)，我们有

![](http://upload-images.jianshu.io/upload_images/42741-1417ab58f98e01bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对此方程关于 $$a$$ 进行积分，得到 

![](http://upload-images.jianshu.io/upload_images/42741-9e1525eab19cfa01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$constant$$ 是积分常量。这是一个单独的训练样本 $$x$$ 对代价函数的贡献。为了得到整个的代价函数，我们需要对所有的训练样本进行平均，得到了

![](http://upload-images.jianshu.io/upload_images/42741-5f594db7abf56be1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而这里的常量就是所有单独的常量的平均。所以我们看到方程(71)和(72)唯一确定了交叉熵的形式，并加上了一个常量的项。这个交叉熵并不是凭空产生的。而是一种我们以自然和简单的方法获得的结果。

那么交叉熵直觉含义又是什么？我们如何看待它？深入解释这一点会将我们带到一个不大愿意讨论的领域。然而，还是值得提一下，有一种源自信息论的解释交叉熵的标准方式。粗略地说，交叉熵是惊奇的度量（measure of surprise）。特别地，我们的神经元想要要计算函数 $$x\rightarrow y=y(x)$$。但是，它用函数$$x\rightarrow a=a(x)$$ 进行了替换。假设我们将 $$a$$ 想象成我们神经元估计 $$y = 1$$ 概率，而 $$1-a$$ 则是 $$y=0$$ 的概率。如果输出我们期望的结果，惊奇就会小一点；反之，惊奇就大一些。当然，我这里没有严格地给出“惊奇”到底意味着什么，所以看起来像在夸夸奇谈。但是实际上，在信息论中有一种准确的方式来定义惊奇究竟是什么。不过，我也不清楚在网络上，哪里有好的，短小的自包含对这个内容的讨论。但如果你要深入了解的话，Wikipedia 包含一个[简短的总结](http://en.wikipedia.org/wiki/Cross_entropy#Motivation)，这会指引你正确地探索这个领域。而更加细节的内容，你们可以阅读[Cover and Thomas](http://books.google.ca/books?id=VWq5GG6ycxMC)的第五章涉及 Kraft 不等式的有关信息论的内容。

### 问题
* 我们已经深入讨论了使用二次代价函数的网络中在输出神经元饱和时候学习缓慢的问题，另一个可能会影响学习的因素就是在方程(61)中的 $$x_j$$ 项。由于此项，当输入 $$x_j$$ 接近 $$0$$ 时，对应的权重 $$x_j$$ 会学习得相当缓慢。解释为何不可以通过改变代价函数来消除 $$x_j$$ 项的影响。
## Softmax
本章，我们大多数情况会使用交叉熵来解决学习缓慢的问题。但是，我希望简要介绍一下基于 softmax 神经元层的解决这个问题的另一种观点。我们不会实际在剩下的章节中使用 softmax 层，所以你如果赶时间，就可以跳到下一个小节了。不过，softmax 仍然有其重要价值，一方面它本身很有趣，另一方面，因为我们会在第六章在对深度神经网络的讨论中使用 softmax 层。

softmax 的想法其实就是为神经网络定义一种新式的输出层。开始时和 sigmoid 层一样的，首先计算带权输入 $$z_j^L = \sum_k w_{jk}^La_k^{L-1}+b_j^L$$。不过，这里我们不会使用 sigmoid 函数来获得输出。而是，会应用一种叫做 softmax 函数在 $$z_j^L$$ 上。根据这个函数，激活值 $$a_j^L$$ 就是

![](http://upload-images.jianshu.io/upload_images/42741-b84180005a015ffc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，分母是对所有的输出神经元进行求和。

如果你不习惯这个函数，方程(78)可能看起来会比较难理解。因为对于使用这个函数的原因你不清楚。为了更好地理解这个公式，假设我们有一个包含四个输出神经元的神经网络，对应四个带权输入，表示为 $$z_1^L, z_2^L, z_3^L, z_4^L$$。下面的例子可以进行对应权值的调整，并给出对应的激活值的图像。可以通过固定其他值，来看看改变 $$z_4^L$$ 的值会产生什么样的影响：

![1](http://upload-images.jianshu.io/upload_images/42741-d21cb21704e16879.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![2](http://upload-images.jianshu.io/upload_images/42741-b2b1987aa0501ef6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![3](http://upload-images.jianshu.io/upload_images/42741-9ba8de22bc879ab7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 这里给出了三个选择的图像，建议去原网站体验

在我们增加 $$z_4^L$$ 的时候，你可以看到对应激活值 $$a_4^L$$ 的增加，而其他的激活值就在下降。类似地，如果你降低 $$z_4^L$$ 那么 $$a_4^L$$ 就随之下降。实际上，如果你仔细看，你会发现在两种情形下，其他激活值的整个改变恰好填补了 $$a_4^L$$ 的变化的空白。原因很简单，根据定义，输出的激活值加起来正好为 $$1$$，使用公式(78)我们可以证明：

![](http://upload-images.jianshu.io/upload_images/42741-56656f179bd9308a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

所以，如果 $$a_4^L$$ 增加，那么其他输出激活值肯定会总共下降相同的量，来保证和式为 $$1$$。当然，类似的结论对其他的激活函数也需要满足。

方程(78)同样保证输出激活值都是正数，因为指数函数是正的。将这两点结合起来，我们看到 softmax 层的输出是一些相加为 $$1$$ 正数的集合。换言之，softmax 层的输出可以被看做是一个概率分布。

这样的效果很令人满意。在很多问题中，将这些激活值作为网络对于某个输出正确的概率的估计非常方便。所以，比如在 MNIST 分类问题中，我们可以将 $$a_j^L$$ 解释成网络估计正确数字分类为 $$j$$ 的概率。

对比一下，如果输出层是 sigmoid 层，那么我们肯定不能假设激活值形成了一个概率分布。我不会证明这一点，但是源自 sigmoid 层的激活值是不能够形成一种概率分布的一般形式的。所以使用 sigmoid 输出层，我们没有关于输出的激活值的简单的解释。

### 练习
* 构造例子表明在使用 sigmoid 输出层的网络中输出激活值 $$a_j^L$$ 的和并不会确保为 $$1$$。

我们现在开始体会到 softmax 函数的形式和行为特征了。来回顾一下：在公式(78)中的指数函数确保了所有的输出激活值是正数。然后分母的求和又保证了 softmax 的输出和为 $$1$$。所以这个特定的形式不再像之前那样难以理解了：反而是一种确保输出激活值形成一个概率分布的自然的方式。你可以将其想象成一种重新调节 $$z_j^L$$   的方法，然后将这个结果整合起来构成一个概率分布。

### 练习
* **softmax 的单调性** 证明如果 $$j=k$$ 则 $$\partial a_j^L/\partial z_k^L$$ 为正，否则为负。结果是，增加 $$z_k^L$$ 会提高对应的输出激活值 $$a_k^L$$ 并降低其他所有输出激活值。我们已经在滑条示例中实验性地看到了这一点，这里需要你给出一个严格证明。
* **softmax 的非局部性** sigmoid 层的一个好处是输出 $$a_j^L$$ 是对应带权输入 $$a_j^L = \sigma(z_j^L)$$ 的函数。解释为何对于 softmax 来说，并不是这样的情况：仍和特定的输出激活值 $$a_j^L$$ 依赖所有的带权输入。

### 问题
* **逆转 softmax 层** 假设我们有一个使用 softmax 输出层的神经网络，然后激活值 $$a_j^L$$ 已知。证明对应带权输入的形式为 $$z_j^L = \ln a_j^L + C$$，其中 $$C$$ 是独立于 $$j$$ 的。

**学习缓慢问题**：我们现在已经对 softmax 神经元有了一定的认识。但是我们还没有看到 softmax 会怎么样解决学习缓慢问题。为了理解这点，先定义一个 log-likelihood 代价函数。我们使用 $$x$$ 表示训练输入，$$y$$ 表示对应的目标输出。然后关联这个训练输入样本的 log-likelihood 代价函数就是

![](http://upload-images.jianshu.io/upload_images/42741-c6a82eff60626d3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

所以，如果我们训练的是 MNIST 图像，输入为 $$7$$ 的图像，那么对应的 log-likelihood 代价就是 $$-\ln a_7^L$$。看看这个直觉上的含义，想想当网络表现很好的时候，也就是确认输入为 $$7$$ 的时候。这时，他会估计一个对应的概率 $$a_7^L$$ 跟 $$1$$ 非常接近，所以代价 $$-\ln a_7^L$$ 就会很小。反之，如果网络的表现糟糕时，概率 $$a_7^L$$ 就变得很小，代价 $$-\ln a_7^L$$ 随之增大。所以 log-likelihood 代价函数也是满足我们期待的代价函数的条件的。

那关于学习缓慢问题呢？为了分析它，回想一下学习缓慢的关键就是量 $$\partial C/\partial w_{jk}^L$$ 和 $$\partial C/\partial b_j^L$$ 的变化情况。我不会显式地给出详细的推导——请你们自己去完成这个过程——但是会给出一些关键的步骤：


![](http://upload-images.jianshu.io/upload_images/42741-2ca3c9d2f0c4d8a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 请注意这里的表示上的差异，这里的 $$y$$ 和之前的目标输出值不同，是离散的向量表示，对应位的值为 $$1$$，而其他为 $$0$$。
这些方程其实和我们前面对交叉熵得到的类似。就拿方程(82) 和 (67) 比较。尽管后者我对整个训练样本进行了平均，不过形式还是一致的。而且，正如前面的分析，这些表达式确保我们不会遇到学习缓慢的问题。实际上，将 softmax 输出层和 log-likelihood 组合对照 sigmoid 输出层和交叉熵的组合类比着看是非常有用的。

有了这样的相似性，你会使用哪一种呢？实际上，在很多应用场景中，这两种方式的效果都不错。本章剩下的内容，我们会使用 sigmoid 输出层和交叉熵的组合。后面，在第六章中，我们有时候会使用 softmax 输出层和 log-likelihood 的则和。切换的原因就是为了让我们的网络和某些在具有影响力的学术论文中的形式更为相似。作为一种更加通用的视角，softmax 加上 log-likelihood 的组合更加适用于那些需要将输出激活值解释为概率的场景。当然这不总是合理的，但是在诸如 MNIST 这种有着不重叠的分类问题上确实很有用。

### 问题
* 推导方程(81) 和 (82)
* **softmax 这个名称从何处来？** 假设我们改变一下 softmax 函数，使得输出激活值定义如下

![](http://upload-images.jianshu.io/upload_images/42741-5b3e8cf9fceece21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$c$$ 是正的常量。注意 $$c=1$$ 对应标准的 softmax 函数。但是如果我们使用不同的 $$c$$ 得到不同的函数，其实最终的量的结果却和原来的 softmax 差不多。特别地，证明输出激活值也会形成一个概率分布。假设我们允许 $$c$$ 足够大，比如说 $$c\rightarrow \infty$$。那么输出激活值 $$a_j^L$$ 的极限值是什么？在解决了这个问题后，你应该能够理解 $$c=1$$ 对应的函数是一个最大化函数的 softened 版本。这就是 softmax 的来源。
> 这让我联想到 EM 算法，对 k-Means 算法的一种推广。

* **softmax 和 log-likelihood 的反向传播** 上一章，我们推到了使用 sigmoid 层的反向传播算法。为了应用在 softmax 层的网络上，我们需要搞清楚最后一层上误差的表示 $$\delta_j^L \equiv \partial C/\partial z_j^L$$。证明形式如下：

![](http://upload-images.jianshu.io/upload_images/42741-73905c0ac973a00d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用这个表达式，我们可以应用反向传播在采用了 softmax 输出层和 log-likelihood 的网络上。

## 过匹配和规范化
---
诺贝尔奖得主美籍意大利裔物理学家恩里科·费米曾被问到他对一个同僚提出的尝试解决一个重要的未解决物理难题的数学模型。模型和实验非常匹配，但是费米却对其产生了怀疑。他问模型中需要设置的自由参数有多少个。答案是“4”。费米回答道：“我记得我的朋友约翰·冯·诺依曼过去常说，有四个参数，我可以模拟一头大象，而有五个参数，我还能让他卷鼻子。”

这里，其实是说拥有大量的自由参数的模型能够描述特别神奇的现象。即使这样的模型能够很好的拟合已有的数据，但并不表示是一个好模型。因为这可能只是因为模型中足够的自由度使得它可以描述几乎所有给定大小的数据集，不需要对现象的本质有创新的认知。所以发生这种情形时，模型对已有的数据会表现的很好，但是对新的数据很难泛化。对一个模型真正的测验就是它对没有见过的场景的预测能力。

费米和冯·诺依曼对有四个参数的模型就开始怀疑了。我们用来对 MNIST 数字分类的 $$30$$ 个隐藏神经元神经网络拥有将近  $$24,000$$ 个参数！当然很多。我们有 $$100$$ 个隐藏元的网络拥有将近 $$80,000$$ 个参数，而目前最先进的深度神经网络包含百万级或者十亿级的参数。我们应当信赖这些结果么？

让我们将问题暴露出来，通过构造一个网络泛化能力很差的例子。我们的网络有 $$30$$ 个隐藏神经元，共 $$23,860$$ 个参数。但是我们不会使用所有 $$50,000$$ 幅训练图像。相反，我们只使用前 $$1000$$ 幅图像。使用这个受限的集合，会让泛化的问题突显。按照同样的方式，使用交叉熵代价函数，学习率设置为 $$\eta=0.5$$ 而 minibatch 大小设置为 $$10$$。不过这里我们训练回合设置为 $$400$$，比前面的要多很多，因为我们只用了少量的训练样本。我们现在使用 `network2` 来研究代价函数改变的情况：
```python
>>> import mnist_loader 
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
>>> import network2 
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost) 
>>> net.large_weight_initializer()
>>> net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data,
... monitor_evaluation_accuracy=True, monitor_training_cost=True)
```

使用上面的结果，我们可以画出代价函数变化的情况：


![](http://upload-images.jianshu.io/upload_images/42741-7cbc8fa8702db64b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这看起来令人振奋，因为代价函数有一个光滑的下降，跟我们预期一致。注意，我只是展示了 $$200$$ 到 $$399$$ 回合的情况。这给出了很好的近距离理解训练后期的情况，这也是出现有趣现象的地方。

让我们看看分类准确度在测试集上的表现：

![](http://upload-images.jianshu.io/upload_images/42741-94ea4772483ee096.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里我还是聚焦到了后面的过程。 在前 $$200$$ 回合（图中没有显示）准确度提升到了 82%。然后学习逐渐变缓。最终，在 $$280$$ 回合左右分类准确度就停止了增长。后面的回合，仅仅看到了在 $$280$$ 回合准确度周围随机的震荡。将这幅图和前面的图进行对比，和训练数据相关的代价函数持续平滑下降。如果我们只看哪个代价，我们会发现模型的表现变得“更好”。但是测试准确度展示了提升只是一种假象。就像费米不大喜欢的那个模型一样，我们的网络在 $$280$$ 回合后就不在能够繁华到测试数据上。所以这种学习不大有用。也可以说网络在 $$280$$ 后就过匹配（或者过度训练）了。

你可能想知道这里的问题是不是由于我们看的是训练数据的代价，而对比的却是测试数据上的分类准确度导致的。换言之，可能我们这里在进行苹果和橙子的对比。如果我们比较训练数据上的代价和测试数据上的代价，会发生什么，我们是在比较类似的度量么？或者可能我们可以比较在两个数据集上的分类准确度啊？实际上，不管我们使用什么度量的方式尽管，细节会变化，但本质上都是一样的。
让我们来看看测试数据集上的代价变化情况：

![](http://upload-images.jianshu.io/upload_images/42741-fea306d4ef3b4c21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以看到测试集上的代价在 $$15$$ 回合前一直在提升，随后越来越差，尽管训练数据机上的代价表现是越来越好的。这其实是另一种模型过匹配的标志。尽管，这里带来了关于我们应当将 $$15$$ 还是 $$280$$ 回合当作是过匹配占主导的时间点的困扰。从一个实践角度，我们真的关心的是提升测试数据集上的分类准确度，而测试集合上的代价不过是分类准确度的一个反应。所以更加合理的选择就是将 $$280$$ 看成是过匹配开始占统治地位的时间点。

另一个过匹配的信号在训练数据上的分类准确度上也能看出来：

![](http://upload-images.jianshu.io/upload_images/42741-70e10d8f73a2b57a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

准确度一直在提升接近 100%。也就是说，我们的网络能够正确地对所有 $$1000$$ 幅图像进行分类！而在同时，我们的测试准确度仅仅能够达到 82.27%。所以我们的网络实际上在学习训练数据集的特例，而不是能够一般地进行识别。我们的网络几乎是在单纯记忆训练集合，而没有对数字本质进行理解能够泛化到测试数据集上。

过匹配是神经网络的一个主要问题。这在现代网络中特别正常，因为网络权重和偏差数量巨大。为了高效地训练，我们需要一种检测过匹配是不是发生的技术，这样我们不会过度训练。并且我们也想要找到一些技术来降低过匹配的影响。

检测过匹配的明显方法是使用上面的方法——跟踪测试数据集合上的准确度随训练变化情况。如果我们看到测试数据上的准确度不再提升，那么我们就停止训练。当然，严格地说，这其实并非是过匹配的一个必要现象，因为测试集和训练集上的准确度可能会同时停止提升。当然，采用这样的方式是可以阻止过匹配的。

实际上，我们会使用这种方式变形来试验。记得之前我们载入 MNIST 数据的时候有：
```python 
>>> import mnist_loader 
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
```

到现在我们一直在使用 `training_data` 和 `test_data`，没有用过 `validation_data`。`validation_data` 中包含了 $$10,000$$ 幅数字图像，这些图像和训练数据集中的 $$50,000$$ 幅图像以及测试数据集中的 $$10,000$$ 幅都不相同。我们会使用 `validation_data` 来防止过匹配。我们会使用和上面应用在 `test_data` 的策略。我们每个回合都计算在 `validation_data` 上的分类准确度。一旦分类准确度已经饱和，就停止训练。这个策略被称为 **提前停止**（Early stopping）。当然，实际应用中，我们不会立即知道什么时候准确度会饱和。相反，我们会一直训练知道我们确信准确度已经饱和。
> 这里需要一些判定标准来确定什么时候停止。在我前面的图中，将 $$280$$ 回合看成是饱和的地方。可能这有点太悲观了。因为神经网络有时候会训练过程中处在一个平原期，然后又开始提升。如果在 $$400$$ 回合后，性能又开始提升（也许只是一些少量提升），那我也不会诧异。所以，在**提前停止**中采取一点激进的策略也是可以的。

为何要使用 `validation_data` 来替代 `test_data` 防止过匹配问题？实际上，这是一个更为一般的策略的一部分，这个一般的策略就是使用 `validation_data` 来衡量不同的超参数（如训练回合，学习率，最好的网络架构等等）的选择的效果。我们使用这样方法来找到超参数的合适值。因此，尽管到现在我并没有提及这点，但其实本书前面已经稍微介绍了一些超参数选择的方法。

当然，这对于我们前面关于 `validation_data` 取代 `test_data` 来防止过匹配的原因仍旧没有回答。实际上，有一个更加一般的问题，就是为何用`validation_data` 取代 `test_data` 来设置更好的超参数？为了理解这点，想想当设置超参数时，我们想要尝试许多不同的超参数选择。如果我们设置超参数是基于 `test_data` 的话，可能最终我们就会得到过匹配于 `test_data` 的超参数。也就是说，我们可能会找到那些 符合 `test_data` 特点的超参数，但是网络的性能并不能够泛化到其他数据集合上。我们借助 `validation_data` 来克服这个问题。然后一旦获得了想要的超参数，最终我们就使用 `test_data` 进行准确度测量。这给了我们在 `test_data` 上结果是一个网络泛化能力真正的度量方式的信心。换言之，你可以将验证集看成是一种特殊的训练数据集能够帮助我们学习好的超参数。这种寻找好的超参数的观点有时候被称为 **hold out** 方法，因为 `validation_data` 是从训练集中保留出来的一部分。

在实际应用中，甚至在衡量了测试集上的性能后，我们可能也会改变想法并去尝试另外的方法——也许是一种不同的网络架构——这将会引入寻找新的超参数的的过程。如果我们这样做，难道不会产生过匹配于 `test_data` 的困境么？我们是不是需要一种潜在无限大的数据集的回归，这样才能够确信模型能够泛化？去除这样的疑惑其实是一个深刻而困难的问题。但是对实际应用的目标，我们不会担心太多。相反，我们会继续采用基于 `training_data, validation_data, and test_data` 的基本 hold out 方法。

我们已经研究了在使用 $$1,000$$ 幅训练图像时的过匹配问题。那么如果我们使用所有的训练数据会发生什么？我们会保留所有其他的参数都一样（$$30$$ 个隐藏元，学习率 $$0.5$$，mini-batch 规模为 $$10$$），但是训练回合为 $$30$$ 次。下图展示了分类准确度在训练和测试集上的变化情况。注意我们使用的测试数据，而不是验证集合，为了让结果看起来和前面的图更方便比较。

![](http://upload-images.jianshu.io/upload_images/42741-c047405fe3544290.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如你所见，测试集和训练集上的准确度相比我们使用 $$1,000$$ 个训练数据时相差更小。特别地，在训练数据上的最佳的分类准确度 97.86% 只比测试集上的 95.33% 准确度高一点点。而之前的例子中，这个差距是 17.73%！过匹配仍然发生了，但是已经减轻了不少。我们的网络从训练数据上更好地泛化到了测试数据上。一般来说，最好的降低过匹配的方式之一就是增加训练样本的量。有了足够的训练数据，就算是一个规模非常大的网络也不大容易过匹配。不幸的是，训练数据其实是很难或者很昂贵的资源，所以这不是一种太切实际的选择。

### 规范化
增加训练样本的数量是一种减轻过匹配的方法。还有其他的一下方法能够减轻过匹配的程度么？一种可行的方式就是降低网络的规模。然而，大的网络拥有一种比小网络更强的潜力，所以这里存在一种应用冗余性的选项。

幸运的是，还有其他的技术能够缓解过匹配，即使我们只有一个固定的网络和固定的训练集合。这种技术就是**规范化**。本节，我会给出一种最为常用的规范化手段——有时候被称为权重下降（weight decay）或者 **L2** 规范化。**L2** 规范化的想法是增加一个额外的项到代价函数上，这个项叫做 **规范化** 项。下面是规范化交叉熵：

![](http://upload-images.jianshu.io/upload_images/42741-c568fcb86507d225.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中第一个项就是常规的交叉熵的表达式。第二个现在加入到就是所有权重的平方的和。然后使用一个因子 $$\lambda/2n$$ 进行量化调整，其中 $$\lambda > 0$$ 可以成为 **规范化参数**，而 $$n$$ 就是训练集合的大小。我们会在后面讨论 $$\lambda$$ 的选择策略。需要注意的是，规范化项里面并不包含偏差。这点我们后面也会在讲述。

当然，对其他的代价函数也可以进行规范化，例如二次代价函数。类似的规范化的形式如下：

![](http://upload-images.jianshu.io/upload_images/42741-5ac129550876960e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

两者都可以写成这样：

![](http://upload-images.jianshu.io/upload_images/42741-c40865987f69098c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$C_0$$ 是原始的代价函数。

直觉地看，规范化的效果是让网络倾向于学习小一点的权重，其他的东西都一样的。大的权重只有能够给出代价函数第一项足够的提升时才被允许。换言之，规范化可以当做一种寻找小的权重和最小化原始的代价函数之间的折中。这两部分之前相对的重要性就由 $$\lambda$$ 的值来控制了：$$\lambda$$ 越小，就偏向于最小化原始代价函数，反之，倾向于小的权重。

现在，对于这样的折中为何能够减轻过匹配还不是很清楚！但是，实际表现表明了这点。我们会在下一节来回答这个问题。但现在，我们来看看一个规范化的确减轻过匹配的例子。

为了构造这个例子，我们首先需要弄清楚如何将随机梯度下降算法应用在一个规范化的神经网络上。特别地，我们需要知道如何计算偏导数 $$\partial C/\partial w$$ 和  $$\partial C/\partial b$$。对公式(87)进行求偏导数得：

![](http://upload-images.jianshu.io/upload_images/42741-5245cdeb7e21cfa6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

$$\partial C_0/\partial w$$ 和  $$\partial C_0/\partial b$$ 可以通过反向传播进行计算，和上一章中的那样。所以我们看到其实计算规范化的代价函数的梯度是很简单的：仅仅需要反向传播，然后加上 $$\frac{\lambda}{n} w$$ 得到所有权重的偏导数。而偏差的偏导数就不要变化，所以梯度下降学习规则不会发生变化：

![](http://upload-images.jianshu.io/upload_images/42741-e799b9aa2f4bfde1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

权重的学习规则就变成：

![](http://upload-images.jianshu.io/upload_images/42741-d67877a26e275e8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这其实和通常的梯度下降学习规则相同欧诺个，除了乘了 $$1-\frac{\eta\lambda}{n}$$ 因子。这里就是**权重下降**的来源。粗看，这样会导致权重会不断下降到 $$0$$。但是实际不是这样的，因为如果在原始代价函数中造成下降的话其他的项可能会让权重增加。

好的，这就是梯度下降工作的原理。那么随机梯度下降呢？正如在没有规范化的随机梯度下降中，我们可以通过平均 minibatch 中 $$m$$ 个训练样本来估计 $$\partial C_0/\partial w$$。因此，为了随机梯度下降的规范化学习规则就变成（参考 方程(20)）

![](http://upload-images.jianshu.io/upload_images/42741-8250a8cd3dbd1d84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中后面一项是对 minibatch 中的训练样本 $$x$$ 进行求和，而 $$C_x$$ 是对每个训练样本的（无规范化的）代价。这其实和之前通常的随机梯度下降的规则是一样的，除了有一个权重下降的因子 $$1-\frac{\eta\lambda}{n}$$。最后，为了完备性，我给出偏差的规范化的学习规则。这当然是和我们之前的非规范化的情形一致了（参考公式(32)）

![](http://upload-images.jianshu.io/upload_images/42741-52af952c5409f9e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里也是对minibatch 中的训练样本 $$x$$ 进行求和的。

让我们看看规范化给网络带来的性能提升吧。这里还会使用有 $$30$$ 个隐藏神经元、minibatch 为 $$10$$，学习率为 $$0.5$$，使用交叉熵的神经网络。然而，这次我们会使用规范化参数为 $$\lambda = 0.1$$。注意在代码中，我们使用的变量名字为 `lmbda`，这是因为在 Python 中 `lambda` 是关键字，尤其特定的作用。我也会使用 `test_data`，而不是 `validation_data`。**不过严格地讲，我们应当使用 `validation_data`的，因为前面已经讲过了。**这里我这样做，是因为这会让结果和非规范化的结果对比起来效果更加直接。你可以轻松地调整为 `validation_data`，你会发现有相似的结果。
```python
>>> import mnist_loader 
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper() 
>>> import network2 
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)
>>> net.large_weight_initializer()
>>> net.SGD(training_data[:1000], 400, 10, 0.5,
... evaluation_data=test_data, lmbda = 0.1,
... monitor_evaluation_cost=True, monitor_evaluation_accuracy=True,
... monitor_training_cost=True, monitor_training_accuracy=True)
```

训练集上的代价函数持续下降，和前面无规范化的情况一样的规律：

![](http://upload-images.jianshu.io/upload_images/42741-229b1ba93198bd50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但是这里测试集上的准确度是随着回合次数持续增加的：

![](http://upload-images.jianshu.io/upload_images/42741-80b1ec26a649b70d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

显然，规范化的使用能够解决过匹配的问题。而且，准确度相当搞了，最高处达到了 87.1%，相较于之前的 82.27%。因此，我们几乎可以确信持续训练会有更加好的结果。实验起来，规范化让网络具有更好的泛化能力，显著地减轻了过匹配的效果。

如果我们换成全部的训练数据进行训练呢？当然，我们之前已经看到过匹配在大规模的数据上其实不是那么明显了。那规范化能不能起到相应的作用呢？保持超参数和之前一样。不过我们这里需要改变规范化参数。原因在于训练数据的大小已经从 $$n=1,000$$ 改成了 $$n=50,000$$，这个会改变权重下降因子 $$1-\frac{\eta\lambda}{n}$$。如果我们持续使用 $$\lambda = 0.1$$ 就会产生很小的权重下降，因此就将规范化的效果降低很多。我们通过将 $$\lambda = 5.0$$ 来补偿这种下降。

好了，来训练网络，重新初始化权重：
```python
>>> net.large_weight_initializer()
>>> net.SGD(training_data, 30, 10, 0.5,
... evaluation_data=test_data, lmbda = 5.0,
... monitor_evaluation_accuracy=True, monitor_training_accuracy=True)
```

我们得到：

![](http://upload-images.jianshu.io/upload_images/42741-6cd0a85cebd14cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这个结果很不错。第一，我们在测试集上的分类准确度在使用规范化后有了提升，从 95.49% 到 96.49%。这是个很大的进步。第二，我们可以看到在训练数据和测试数据上的结果之间的差距也更小了。这仍然是一个大的差距，不过我们已经显著得到了本质上的降低过匹配的进步。

最后，我们看看在使用 $$100$$ 个隐藏元和规范化参数为 $$\lambda = 5.0$$ 相应的测试分类准确度。我不会给出详细分析，就为了有趣，来看看我们使用一些技巧（交叉熵函数和 $$L2$$ 规范化）能够达到多高的准确度。
```python
>>> net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)
>>> net.large_weight_initializer()
>>> net.SGD(training_data, 30, 10, 0.5, lmbda=5.0,
... evaluation_data=validation_data,
... monitor_evaluation_accuracy=True)
```

最终在验证集上的准确度达到了 97.92%。这是比 $$30$$ 个隐藏元的较大飞跃。实际上，稍微改变一点，$$60$$ 回合 $$\eta=0.1$$ 和 $$\lambda = 5.0$$。我们就突破了 98%，达到了 98.04% 的分类准确度。对于 $$152$$ 行代码这个效果还真不错！

我们讨论了作为一种减轻过匹配和提高分类准确度的方式的规范化技术。实际上，这不是仅有的好处。实践表明，在使用不同的（随机）权重初始化进行多次 MNIST 网络训练的时候，我发现无规范化的网络会偶然被限制住，明显困在了代价函数的局部最优值处。结果就是不同的运行会给出相差很大的结果。对比看来，规范化的网络能够提供更容易复制的结果。

为何会这样子？从经验上看，如果代价函数是无规范化的，那么权重向量的长度可能会增长，而其他的东西都保持一样。随着时间的推移，这个会导致权重向量变得非常大。所以会使得权重向困在差不多方向上，因为由于梯度下降的改变当长度很大的时候仅仅会在那个方向发生微小的变化。我相信这个现象让学习算法更难有效地探索权重空间，最终导致很难找到代价函数的最优值。

### 为何规范化可以帮助减轻过匹配
我们已经看到了规范化在实践中能够减少过匹配了。这是令人振奋的，不过，这背后的原因还不得而知！通常的说法是：小的权重在某种程度上，意味着更低的复杂性，也就给出了一种更简单却更强大的数据解释，因此应该优先选择。这虽然很简短，不过暗藏了一些可能看起来会令人困惑的因素。让我们将这个解释细化，认真地研究一下。现在给一个简单的数据集，我们为其建立模型：

![](http://upload-images.jianshu.io/upload_images/42741-201962e2a60f23c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里我们其实在研究某种真实的现象，$$x$$ 和 $$y$$ 表示真实的数据。我们的目标是训练一个模型来预测 $$y$$ 关于 $$x$$ 的函数。我们可以使用神经网络来构建这个模型，但是我们先来个简单的：用一个多项式来拟合数据。这样做的原因其实是多项式相比神经网络能够让事情变得更加清楚。一旦我们理解了多项式的场景，对于神经网络可以如法炮制。现在，图中有十个点，我们就可以找到唯一的 $$9$$ 阶多项式 $$y=a_0x^9 + a_1x^8 + ... + a_9$$ 来完全拟合数据。下面是多项式的图像：
> I won't show the coefficients explicitly, although they are easy to find using a routine such as Numpy's polyfit. You can view the exact form of the polynomial in the [source code for the  graph](http://neuralnetworksanddeeplearning.com/js/polynomial_model.js) if you're curious. It's the function p(x) defined starting on line 14 of the program which produces the graph.


![](http://upload-images.jianshu.io/upload_images/42741-4cdc199955f4cfcd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这给出了一个完美的拟合。但是我们同样也能够使用线性模型 $$y=2x$$ 得到一个好的拟合效果：

![](http://upload-images.jianshu.io/upload_images/42741-3ecb8d8ac1eeafd4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

哪个是更好的模型？哪个更可能是真的？还有哪个模型更可能泛化到其他的拥有同样现象的样本上？

这些都是很难回答的问题。实际上，我们如果没有关于现象背后的信息的话，并不能确定给出上面任何一个问题的答案。但是让我们考虑两种可能的情况：（1）$$9$$ 阶多项式实际上是完全描述了真实情况的模型，最终它能够很好地泛化；（2）正确的模型是 $$y=2x$$，但是存在着由于测量误差导致的额外的噪声，使得模型不能够准确拟合。

先验假设无法说出哪个是正确的（或者，如果还有其他的情况出现）。逻辑上讲，这些都可能出现。并且这不是易见的差异。在给出的数据上，两个模型的表现其实是差不多的。但是假设我们想要预测对应于某个超过了图中所有的 $$x$$ 的 $$y$$ 的值，在两个模型给出的结果之间肯定有一个极大的差距，因为 $$9$$ 阶多项式模型肯定会被 $$x^9$$ 主导，而线性模型只是线性的增长。

在科学中，一种观点是我们除非不得已应该追随更简单的解释。当我们找到一个简单模型似乎能够解释很多数据样本的时候，我们都会激动地认为发现了规律！总之，这看起来简单的解决仅仅会是偶然出现的不大可能。我们怀疑模型必须表达出某些关于现象的内在的真理。如上面的例子，线性模型加噪声肯定比多项式更加可能。所以如果简单性是偶然出现的话就很令人诧异。因此我们会认为线性模型加噪声表达除了一些潜在的真理。从这个角度看，多项式模型仅仅是学习到了局部噪声的影响效果。所以尽管多是对于这些特定的数据点表现得很好。模型最终会在未知数据上的泛化上出现问题，所以噪声线性模型具有更强大的预测能力。

让我们从这个观点来看神经网络。假设神经网络大多数有很小的权重，这最可能出现在规范化的网络中。更小的权重意味着网络的行为不会因为我们随便改变了一个输入而改变太大。这会让规范化网络学习局部噪声的影响更加困难。将它看做是一种让单个的证据不会影响网络输出太多的方式。相对的，规范化网络学习去对整个训练集中经常出现的证据进行反应。对比看，大权重的网络可能会因为输入的微小改变而产生比较大的行为改变。所以一个无规范化的网络可以使用大的权重来学习包含训练数据中的噪声的大量信息的复杂模型。简言之，规范化网络受限于根据训练数据中常见的模式来构造相对简单的模型，而能够抵抗训练数据中的噪声的特性影响。我们的想法就是这可以让我们的网络对看到的现象进行真实的学习，并能够根据已经学到的知识更好地进行泛化。

所以，倾向于更简单的解释的想法其实会让我们觉得紧张。人们有时候将这个想法称为“奥卡姆剃刀原则”，然后就会热情地将其当成某种科学原理来应用这个法则。但是，这就不是一个一般的科学原理。也没有任何先验的逻辑原因来说明简单的解释就比更为负责的解释要好。实际上，有时候更加复杂的解释其实是正确的。

让我介绍两个说明复杂正确的例子。在 $$1940$$ 年代，物理学家 Marcel Schein 发布了一个发现新粒子的声明。而他工作的公司，GE，非常欢喜，就广泛地推广这个发现。但是物理学及 Hans Bethe 就有怀疑。Bethe 访问了 Schein，看着那些展示 Schein 的新粒子的轨迹的盘子。但是在每个 plate 上，Bethe 都发现了某个说明数据需要被去除的问题。最后 Schein 展示给 Bethe 一个看起来很好的 plate。Bethe 说这可能就是一个统计上的侥幸。Schein 说，“使得，但是这个可能就是统计学，甚至是根据你自己的公式，也就是 $$1/5$$ 的概率。” Bethe 说：“但我们已经看过了这 $$5$$ 个plate 了”。最终，Schein 说：“但是在我的plate中，每个好的plate，每个好的场景，你使用了不同的理论（说它们是新的粒子）进行解释，而我只有一种假设来解释所有的 plate。” Bethe 回答说，“在你和我的解释之间的唯一差别就是你的是错的，而我所有的观点是正确的。你单一的解释是错误的，我的多重解释所有都是正确的。”后续的工作证实了，Bethe 的想法是正确的而 Schein 粒子不再正确。
> **注意**：这一段翻译得很不好，请参考原文

第二个例子，在 $$1859$$ 年，天文学家 Urbain Le Verrier 观察到水星并没有按照牛顿万有引力给出的轨迹进行运转。与牛顿力学只有很小的偏差，那时候一些解释就是牛顿力学需要一些微小的改动了。在 $$1916$$ 年爱因斯坦证明偏差用他的广义相对论可以解释得更好，这是一种和牛顿重力体系相差很大的理论，基于更复杂的数学。尽管引入了更多的复杂性，现如今爱因斯坦的解释其实是正确的，而牛顿力学即使加入一些调整，仍旧是错误的。这部分因为我们知道爱因斯坦的理论不仅仅解释了这个问题，还有很多其他牛顿力学无法解释的问题也能够完美解释。另外，令人印象深刻的是，爱因斯坦的理论准确地给出了一些牛顿力学没能够预测到的显现。但是这些令人印象深刻的现象其实在先前的时代是观测不到的。如果一个人仅仅通过简单性作为判断合理模型的基础，那么一些牛顿力学的改进理论可能会看起来更加合理一些。

从这些故事中可以读出三点。第一，确定两种解释中哪个“更加简单”其实是一件相当微妙的工作。第二，即使我们可以做出这样一个判断，简单性也是一个使用时需要相当小心的指导！第三，对模型真正的测试不是简单性，而是它在新场景中对新的活动中的预测能力。

所以，我们应当时时记住这一点，规范化的神经网络常常能够比非规范化的泛化能力更强，这只是一种实验事实（empirical fact）。所以，本书剩下的内容，我们也会频繁地使用规范化技术。我已经在上面讲过了为何现在还没有一个人能够发展出一整套具有说服力的关于规范化可以帮助网络泛化的理论解释。实际上，研究者们不断地在写自己尝试不同的规范化方法，然后看看哪种表现更好，尝试理解为何不同的观点表现的更好。所以你可以将规范化看做某种任意整合的技术。尽管其效果不错，但我们并没有一套完整的关于所发生情况的理解，仅仅是一些不完备的启发式规则或者经验。

这里也有更深的问题，这个问题也是有关科学的关键问题——我们如何泛化。规范化能够给我们一种计算上的魔力帮助神经网络更好地泛化，但是并不会带来原理上理解的指导，甚至不会告诉我们什么样的观点才是最好的。
> 这个问题要追溯到[归纳问题](http://en.wikipedia.org/wiki/Problem_of_induction)，最先由苏格兰哲学家大卫 休谟在 ["An Enquiry Concerning Human Understanding"](http://www.gutenberg.org/ebooks/9662)(1748) 中提出。在现代机器学习领域中归纳问题被 David Wolpert 和 William Macready 描述成[无免费午餐定理](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=585893)。

这实在是令人困扰，因为在日常生活中，我们人类在泛化上表现很好。给一个儿童几幅大象的图片，他就能快速地学会认识其他的大象。当然，他们偶尔也会搞错，很可能将一只犀牛误认为大象，但是一般说来，这个过程会相当准确。所以我们有个系统——人的大脑——拥有超大量的自由变量。在受到仅仅少量的训练图像后，系统学会了在其他图像的推广。某种程度上，我们的大脑的规范化做得特别好！怎么做的？现在还不得而知。我期望若干年后，我们能够发展出更加强大的技术来规范化神经网络，最终这些技术会让神经网络甚至在小的训练集上也能够学到强大的泛化能力。

实际上，我们的网络已经比我们预先期望的要好一些了。拥有 $$100$$ 个隐藏元的网络会有接近 $$80,000$$ 个参数。我们的训练集仅仅有 $$50,000$$ 幅图像。这好像是用一个 $$80,000$$ 阶的多项式来拟合 $$50,000$$ 个数据点。我们的网络肯定会过匹配得很严重。但是，这样的网络实际上却泛化得很好。为什么？这一点并没有很好滴理解。这里有个猜想：梯度下降学习的动态有一种自规范化的效应。这真是一个意料之外的巧合，但也带来了对于这种现象本质无知的不安。不过，我们还是会在后面依照这种实践的观点来应用规范化技术的。
神经网络也是由于这点表现才更好一些。

现在我们回到前面留下来的一个细节：L2 规范化没有限制偏差，以此作为本节的结论。当然了，对规范化的过程稍作调整就可以对偏差进行规范了。实践看来，做出这样的调整并不会对结果改变太多，所以，在某种程度上，对不对偏差进行规范化其实就是一种习惯了。然而，需要注意的是，有一个大的偏差并不会像大的权重那样会让神经元对输入太过敏感。所以我们不需要对大的偏差所带来的学习训练数据的噪声太过担心。同时，允许大的偏差能够让网络更加灵活——因为，大的偏差让神经元更加容易饱和，这有时候是我们所要达到的效果。所以，我们通常不会对偏差进行规范化。

### 规范化的其他技术
除了 L2 外还有很多规范化技术。实际上，正是由于数量众多，我这里也不回将所有的都列举出来。在本节，我简要地给出三种减轻过匹配的其他的方法：L1 规范化、dropout 和人工增加训练样本。我们不会像上面介绍得那么深入。其实，目的只是想让读者熟悉这些主要的思想，然后来体会一下规范化技术的多样性。

**L1 规范化**：这个方法其实是在代价函数上加上一个权重绝对值的和：

![](http://upload-images.jianshu.io/upload_images/42741-4965f6123f128153.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

直觉上看，这和 L2 规范化相似，惩罚大的权重，倾向于让网络的权重变小。当然，L1 规范化和 L2 规范化并不相同，所以我们不应该期望 L1 规范化是进行同样的行为。让我们来看看试着理解使用 L1 规范化和 L2 规范化所不同的地方。

首先，我们会研究一下代价函数的偏导数。对(95)求导我们有：

![](http://upload-images.jianshu.io/upload_images/42741-b4f1bc0df09ede97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$sgn(w)$$ 就是 $$w$$ 的正负号。使用这个表达式，我们可以轻易地对反向传播进行修改从而使用基于 L1 规范化的随机梯度下降进行学习。对 L1 规范化的网络进行更新的规则就是

![](http://upload-images.jianshu.io/upload_images/42741-af9d539b92b9e219.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中和往常一样，我们可以用 minibatch 的均值来估计 $$\partial C_0/\partial w$$。对比公式(93)的 L2 规范化，

![](http://upload-images.jianshu.io/upload_images/42741-2f6516012f4a5439.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在两种情形下，规范化的效果就是缩小权重。这和我们想要让权重不会太大的直觉目标相符。在 L1 规范化中，权重按照一个接近 $$0$$ 的常量进行缩小。在 L2 规范化中，权重同按照一个和 $$w$$ 成比例的量进行缩小的。所以，当一个特定的权重绝对值 $$|w|$$很大时，L1 规范化缩小得远比 L2 规范化要小得多。而一个特定的权重绝对值 $$|w|$$很小时，L1 规范化权值要比 L2 规范化缩小得更大。最终的结果就是：L1 规范化倾向于聚集网络的权重在相对少量的高重要度连接上，而其他权重就会被驱使向 $$0$$ 接近。

我在上面的讨论中其实忽略了一个问题——在 $$w=0$$ 的时候，偏导数 $$\partial C/\partial w$$ 未定义。原因在于函数 $$|w|$$ 在 $$w=0$$ 时有个直角，事实上，导数是不存在的。不过也没有关系。我们下面要做的就是应用无规范化的通常的梯度下降的规则在 $$w=0$$ 处。这应该不会有什么问题，直觉上看，规范化的效果就是缩小权重，显然，不能对一个已经是 $$0$$ 的权重进行缩小了。更准确地说，我们将会使用方程(96)(97)并约定 $$sgn(0)=0$$。这样就给出了一种紧致的规则来进行采用 L1 规范化的随机梯度下降学习。

**Dropout **：Dropout 是一种相当激进的技术。和 L1、L2 规范化不同，dropout 并不依赖对代价函数的变更。而是，在 dropout 中，我们改变了网络本身。让我在给出为何工作的原理之前描述一下 dropout 基本的工作机制和所得到的结果。

假设我们尝试训练一个网络：

![](http://upload-images.jianshu.io/upload_images/42741-bccb282e0e6bdea2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

特别地，假设我们有一个训练数据 $$x$$ 和 对应的目标输出 $$y$$。通常我们会通过在网络中前向传播 $$x$$ ，然后进行反向传播来确定对梯度的共现。使用 dropout，这个过程就改了。我们会从随机（临时）地删除网络中的一半的神经元开始，让输入层和输出层的神经元保持不变。在此之后，我们会得到最终的网络。注意那些被 dropout 的神经元，即那些临时性删除的神经元，用虚圈表示在途中：

![](http://upload-images.jianshu.io/upload_images/42741-1a80626229d2b249.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们前向传播输入，通过修改后的网络，然后反向传播结果，同样通过这个修改后的网络。在 minibatch 的若干样本上进行这些步骤后，我们对那些权重和偏差进行更新。然后重复这个过程，首先重置 dropout 的神经元，然后选择新的随机隐藏元的子集进行删除，估计对一个不同的minibatch的梯度，然后更新权重和偏差。

通过不断地重复，我们的网络会学到一个权重和偏差的集合。当然，这些权重和偏差也是在一般的隐藏元被丢弃的情形下学到的。当我们实际运行整个网络时，是指两倍的隐藏元将会被激活。为了补偿这个，我们将从隐藏元出去的权重减半了。

这个 dropout 过程可能看起来奇怪和ad hoc。为什么我们期待这样的方法能够进行规范化呢？为了解释所发生的事，我希望你停下来想一下没有 dropout 的训练方式。特别地，想象一下我们训练几个不同的神经网络，使用的同一个训练数据。当然，网络可能不是从同一初始状态开始的，最终的结果也会有一些差异。出现这种情况时，我们可以使用一些平均或者投票的方式来确定接受哪个输出。例如，如果我们训练了五个网络，其中三个被分类当做是 $$3$$，那很可能它就是 $$3$$。另外两个可能就犯了错误。这种平均的方式通常是一种强大（尽管代价昂贵）的方式来减轻过匹配。原因在于不同的网络可能会以不同的方式过匹配，平均法可能会帮助我们消除那样的过匹配。

那么这和 dropout 有什么关系呢？启发式地看，当我们丢掉不同的神经元集合时，有点像我们在训练不同的神经网络。所以，dropout 过程就如同大量不同网络的效果的平均那样。不同的网络以不同的方式过匹配了，所以，dropout 的网络会减轻过匹配。

一个相关的启发式解释在早期使用这项技术的论文中曾经给出：“因为神经元不能依赖其他神经元特定的存在，这个技术其实减少了复杂的互适应的神经元。所以，强制要学习那些在神经元的不同随机子集中更加健壮的特征。”换言之，如果我们就爱那个神经网络看做一个进行预测的模型的话，我们就可以将 dropout 看做是一种确保模型对于证据丢失健壮的方式。这样看来，dropout 和 L1、L2 规范化也是有相似之处的，这也倾向于更小的权重，最后让网络对丢失个体连接的场景更加健壮。

当然，真正衡量 dropout 的方式在提升神经网络性能上应用得相当成功。原始论文介绍了用来解决很多不同问题的技术。对我们来说，特别感兴趣的是他们应用 dropout 在 MNIST 数字分类上，使用了一个和我们之前介绍的那种初级的前向神经网络。这篇文章关注到最好的结果是在测试集上去得到 98.4% 的准确度。他们使用dropout 和 L2 规范化的组合将其提高到了 98.7%。类似重要的结果在其他不同的任务上也取得了一定的成效。dropout 已经在过匹配问题尤其突出的训练大规模深度网络中。

**人工扩展训练数据**：我们前面看到了 MNIST 分类准确度在我们使用 $$1,000$$ 幅训练图像时候下降到了 $$80$$ 年代的准确度。这种情况并不奇怪，因为更少的训练数据意味着我们的网络所接触到较少的人类手写的数字中的变化。让我们训练 $$30$$ 个隐藏元的网络，使用不同的训练数据集，来看看性能的变化情况。我们使用 minibatch 大小为 $$10$$，学习率是 $$\eta=0.5$$，规范化参数是 $$\lambda=5.0$$，交叉熵代价函数。我们在全部训练数据集合上训练 30 个回合，然后会随着训练数据量的下降而成比例变化回合数。为了确保权重下降因子在训练数据集上相同，我们会在全部训练集上使用规范化参数为 $$\lambda = 5.0$$，然后在使用更小的训练集的时候成比例地下降 $$\lambda$$ 值。
> This and the next two graph are produced with the program[more_data.py](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/fig/more_data.py).

![](http://upload-images.jianshu.io/upload_images/42741-52e487b1c184b02f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如你所见，分类准确度在使用更多的训练数据时提升了很大。根据这个趋势的话，提升会随着更多的数据而不断增加。当然，在训练的后期我们看到学习过程已经进入了饱和状态。然而，如果我们使用对数作为横坐标的话，可以重画此图如下：

![](http://upload-images.jianshu.io/upload_images/42741-80eaa49e73c6af2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这看起来到了后面结束的地方，增加仍旧明显。这表明如果我们使用大量更多的训练数据——不妨设百万或者十亿级的手写样本——那么，我们可能会得到更好的性能，即使是用这样的简单网络。

获取更多的训练样本其实是很重要的想法。不幸的是，这个方法代价很大，在实践中常常是很难达到的。不过，还有一种方法能够获得类似的效果，那就是进行人工的样本扩展。假设我们使用一个 $$5$$ 的训练样本，

![](http://upload-images.jianshu.io/upload_images/42741-e6d413c3e27dbeb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

将其进行旋转，比如说 $$15$$°：

![](http://upload-images.jianshu.io/upload_images/42741-699fc99b750097cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这还是会被设别为同样的数字的。但是在像素层级这和任何一幅在 MNIST 训练数据中的图像都不相同。所以将这样的样本加入到训练数据中是很可能帮助我们学习有关手写数字更多知识的方法。而且，显然，我们不会就只对这幅图进行人工的改造。我们可以在所有的 MNIST 训练样本上通过和多小的旋转扩展训练数据，然后使用扩展后的训练数据来提升我们网络的性能。

这个想法非常强大并且已经被广发应用了。让我们看看一些在 MNIST 上使用了类似的方法进行研究成果。其中一种他们考虑的网络结构其实和我们已经使用过的类似——一个拥有 800 个隐藏元的前驱神经网络，使用了交叉熵代价函数。在标准的 MNIST 训练数据上运行这个网络，得到了 98.4% 的分类准确度，其中使用了不只是旋转还包括转换和扭曲。通过在这个扩展后的数据集上的训练，他们提升到了 98.9% 的准确度。然后还在“弹性扭曲（elastic distortion）”的数据上进行了实验，这是一种特殊的为了模仿手部肌肉的随机抖动的图像扭曲方法。通过使用弹性扭曲扩展的数据，他们最终达到了 99.3% 的分类准确度。他们通过展示训练数据的所有类型的变体来扩展了网络的经验。
>[Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis](http://dx.doi.org/10.1109/ICDAR.2003.1227801), by Patrice Simard, Dave Steinkraus, and John Platt (2003).

这个想法的变体也可以用在提升手写数字识别之外不同学习任务上的性能。一般就是通过应用反映真实世界变化的操作来扩展训练数据。找到这些方法其实并不困难。例如，你要构建一个神经网络来进行语音识别。我们人类甚至可以在有背景噪声的情况下识别语音。所以你可以通过增加背景噪声来扩展你的训练数据。我们同样能够对其进行加速和减速来获得相应的扩展数据。所以这是另外的一些扩展训练数据的方法。这些技术并不总是有用——例如，其实与其在数据中加入噪声，倒不如先对数据进行噪声的清理，这样可能更加有效。当然，记住可以进行数据的扩展，寻求应用的机会还是相当有价值的一件事。

### 练习
* 正如上面讨论的那样，一种扩展 MNIST 训练数据的方式是用一些微小的旋转。如果我们允许过大的旋转，则会出现什么状况呢？

**大数据的旁白和对分类准确度的影响**：让我们看看神经网络准确度随着训练集大小变化的情况：

![](http://upload-images.jianshu.io/upload_images/42741-9ad74c9f22dbf574.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

假设，我们使用别的什么方法来进行分类。例如，我们使用 SVM。正如第一章介绍的那样，不要担心你熟不熟悉 SVM，我们不进行深入的讨论。下面是 SVM 模型的准确度随着训练数据集的大小变化的情况：

![](http://upload-images.jianshu.io/upload_images/42741-74d22b168f364fd2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可能第一件让你吃惊的是神经网络在每个训练规模下性能都超过了 SVM。这很好，尽管你对细节和原理可能不太了解，因为我们只是直接从 scikit-learn 中直接调用了这个方法，而对神经网络已经深入讲解了很多。更加微妙和有趣的现象其实是如果我们训练 SVM 使用 $$50,000$$ 幅图像，实际上 SVM 已经能够超过我们使用 $$5,000$$ 幅图像的准确度。换言之，更多的训练数据可以补偿不同的机器学习算法的差距。

还有更加有趣的现象也出现了。假设我们试着用两种机器学习算法去解决问题，算法 $$A$$ 和算法 $$B$$。有时候出现，算法 $$A$$ 在一个训练集合上超过 算法 $$B$$，却在另一个训练集上弱于算法 $$B$$。上面我们并没有看到这个情况——因为这要求两幅图有交叉的点——这里并没有。对“算法 A 是不是要比算法 $$B$$ 好？”正确的反应应该是“你在使用什么训练集合？”

在进行开发时或者在读研究论文时，这都是需要记住的事情。很多论文聚焦在寻找新的技术来给出标准数据集上更好的性能。“我们的超赞的技术在标准测试集 $$Y$$ 上给出了百分之 $$X$$ 的性能提升。”这是通常的研究声明。这样的声明通常比较有趣，不过也必须被理解为仅仅在特定的训练数据机上的应用效果。那些给出基准数据集的人们会拥有更大的研究经费支持，这样能够获得更好的训练数据。所以，很可能他们由于超赞的技术的性能提升其实在更大的数据集合上就丧失了。**换言之，人们标榜的提升可能就是历史的偶然。**所以需要记住的特别是在实际应用中，我们想要的是更好的算法和更好的训练数据。寻找更好的算法很重，不过需要确保你在此过程中，没有放弃对更多更好的数据的追求。

### 问题
* **研究问题**：我们的机器学习算法在非常大的数据集上如何进行？对任何给定的算法，其实去定义一个随着训练数据规模变化的渐近的性能是一种很自然的尝试。一种简单粗暴的方法就是简单地进行上面图中的趋势分析，然后将图像推进到无穷大。而对此想法的反驳是曲线本身会给出不同的渐近性能。你能够找到拟合某些特定类别曲线的理论上的验证方法吗？如果可以，比较不同的机器学习算法的渐近性能。

**总结**：我们现在已经介绍完了过匹配和规范化。当然，我们重回这个问题。正如我们前面讲过的那样，尤其是计算机越来越强大，我们有训练更大的网络的能力时。过匹配是神经网络中一个主要的问题。我们有迫切的愿望来开发出强大的规范化技术来减轻过匹配，所以，这也是当前研究的极其热门的方向之一。

## 权重初始化
---
创建了神经网络后，我们需要进行权重和偏差的初始化。到现在，我们一直是根据在第一章中介绍的那样进行初始化。提醒你一下，之前的方式就是根据独立的均值为 $$0$$，标准差为 $$1$$ 的高斯随机变量随机采样作为权重和偏差的初始值。这个方法工作的还不错，但是非常 ad hoc，所以我们需要寻找一些更好的方式来设置我们网络的初始化权重和偏差，这对于帮助网络学习速度的提升很有价值。

结果表明，我们可以比使用正规化的高斯分布效果更好。为什么？假设我们使用一个很多的输入神经元，比如说 $$1000$$。假设，我们已经使用正规化的高斯分布初始化了连接第一隐藏层的权重。现在我将注意力集中在这一层的连接权重上，忽略网络其他部分：

![](http://upload-images.jianshu.io/upload_images/42741-da882a60db0a19f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们为了简化，假设，我们使用训练样本 x 其中一半的神经元值为 $$0$$，另一半为 $$1$$。下面的观点也是可以更加广泛地应用，但是你可以从特例中获得背后的思想。让我们考虑带权和 $$z=\sum_j w_j x_j + b$$ 的隐藏元输入。其中 $$500$$ 个项消去了，因为对应的输入 $$x_j=0$$。所以 $$z$$ 是 $$501$$ 个正规化的高斯随机变量的和，包含 $$500$$ 个权重项和额外的 $$1$$ 个偏差项。因此 $$z$$ 本身是一个均值为 $$0$$ 标准差为 $$\sqrt{501}\approx 22.4$$ 的分布。$$z$$ 其实有一个非常宽的高斯分布，不是非常尖的形状：

![](http://upload-images.jianshu.io/upload_images/42741-5c4ca529cf22c770.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

尤其是，我们可以从这幅图中看出 $$|z|$$ 会变得非常的大，比如说 $$z\gg1$$ 或者 $$z\ll 1$$。如果是这样，输出 $$\sigma(z)$$ 就会接近 $$1$$ 或者 $$0$$。也就表示我们的隐藏元会饱和。所以当出现这样的情况时，在权重中进行微小的调整仅仅会给隐藏元的激活值带来极其微弱的改变。而这种微弱的改变也会影响网络中剩下的神经元，然后会带来相应的代价函数的改变。结果就是，这些权重在我们进行梯度下降算法时会学习得非常缓慢。这其实和我们前面讨论的问题差不多，前面的情况是输出神经元在错误的值上饱和导致学习的下降。我们之前通过代价函数的选择解决了前面的问题。不幸的是，尽管那种方式在输出神经元上有效，但对于隐藏元的饱和却一点作用都没有。

我已经研究了第一隐藏层的权重输入。当然，类似的论断也对后面的隐藏层有效：如果权重也是用正规化的高斯分布进行初始化，那么激活值将会接近 $$0$$ 或者 $$1$$，学习速度也会相当缓慢。

还有可以帮助我们进行更好地初始化么，能够避免这种类型的饱和，最终避免学习速度的下降？假设我们有一个有 $$n_{in}$$ 个输入权重的神经元。我们会使用均值为 $$0$$  标准差为 $$1/\sqrt{n_{in}}$$ 的高斯分布初始化这些权重。也就是说，我们会向下挤压高斯分布，让我们的神经元更不可能饱和。我们会继续使用均值为 $$0$$  标准差为 $$1$$ 的高斯分布来对偏差进行初始化，后面会告诉你原因。有了这些设定，带权和 $$z=\sum_j w_j x_j + b$$ 仍然是一个均值为 $$0$$ 不过有很陡的峰顶的高斯分布。假设，我们有 $$500$$ 个值为 $$0$$ 的输入和$$500$$ 个值为 $$1$$ 的输入。那么很容证明 $$z$$ 是服从均值为 $$0$$ 标准差为 $$\sqrt{3/2} = 1.22$$ 的高斯分布。这图像要比以前陡得多，所以即使我已经对横坐标进行压缩为了进行更直观的比较：

![](http://upload-images.jianshu.io/upload_images/42741-d26b34af43965aab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样的一个神经元更不可能饱和，因此也不大可能遇到学习速度下降的问题。

### 练习
* 验证 $$z=\sum_j w_j x_j + b$$ 标准差为 $$\sqrt{3/2}$$。下面两点可能会有帮助：（a） 独立随机变量的和的方差是每个独立随即便方差的和；（b）方差是标准差的平方。

我在上面提到，我们使用同样的方式对偏差进行初始化，就是使用均值为 $$0$$  标准差为 $$1$$ 的高斯分布来对偏差进行初始化。这其实是可行的，因为这样并不会让我们的神经网络更容易饱和。实际上，其实已经避免了饱和的问题的话，如何初始化偏差影响不大。有些人将所有的偏差初始化为 $$0$$，依赖梯度下降来学习合适的偏差。但是因为差别不是很大，我们后面还会按照前面的方式来进行初始化。

让我们在 MNIST 数字分类任务上比较一下新旧两种权重初始化方式。同样，还是使用 $$30$$ 个隐藏元，minibatch 的大小为 $$30$$，规范化参数 $$\lambda=5.0$$，然后是交叉熵代价函数。我们将学习率从 $$\eta=0.5$$ 调整到 $$0.1$$，因为这样会让结果在图像中表现得更加明显。我们先使用旧的初始化方法训练：
```python
>>> import mnist_loader
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
>>> import network2
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)
>>> net.large_weight_initializer()
>>> net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0,
... evaluation_data=validation_data, 
... monitor_evaluation_accuracy=True)
```

我们也使用新方法来进行权重的初始化。这实际上还要更简单，因为 network2's 默认方式就是使用新的方法。这意味着我们可以丢掉 `net.large_weight_initializer()` 调用：
```python
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)
>>> net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0,
... evaluation_data=validation_data, 
... monitor_evaluation_accuracy=True)
```

将结果用图展示出来，就是：


![](http://upload-images.jianshu.io/upload_images/42741-431bd0e46e5069f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

两种情形下，我们在 96% 的准确度上重合了。最终的分类准确度几乎完全一样。但是新的初始化技术带来了速度的提升。在第一种初始化方式的分类准确度在 87% 一下，而新的方法已经几乎达到了 93%。看起来的情况就是我们新的关于权重初始化的方式将训练带到了一个新的境界，让我们能够更加快速地得到好的结果。同样的情况在 $$100$$ 个神经元的设定中也出现了：

![](http://upload-images.jianshu.io/upload_images/42741-3cd4101d93344f0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在这个情况下，两个曲线并没有重合。然而，我做的实验发现了其实就在一些额外的回合后（这里没有展示）准确度其实也是几乎相同的。所以，基于这些实验，看起来提升的权重初始化仅仅会加快训练，不会改变网络的性能。然而，在第四张，我们会看到一些例子里面使用 $$1/\sqrt{n_{in}}$$ 权重初始化的长期运行的结果要显著更优。因此，不仅仅能够带来训练速度的加快，有时候在最终性能上也有很大的提升。

$$1/\sqrt{n_{in}}$$ 的权重初始化方法帮助我们提升了神经网络学习的方式。其他的权重初始化技术同样也有，很多都是基于这个基本的思想。我不会在这里给出其他的方法，因为 $$1/\sqrt{n_{in}}$$ 已经可以工作得很好了。如果你对另外的思想感兴趣，我推荐你看看在 $$2012$$ 年的 Yoshua Bengio 的论文的 $$14$$ 和 $$15$$ 页，以及相关的参考文献。
> [Practical Recommendations for Gradient-Based Training of Deep Architectures](http://arxiv.org/pdf/1206.5533v2.pdf), by Yoshua Bengio (2012).

### 问题
* **将规范化和改进的权重初始化方法结合使用** L2 规范化有时候会自动给我们一些类似于新的初始化方法的东西。假设我们使用旧的初始化权重的方法。考虑一个启发式的观点：（1）假设$$\lambda$$ 不太小，训练的第一回合将会几乎被权重下降统治。；（2）如果 $$\eta\lambda \ll n$$，权重会按照因子 $$exp(-\eta\lambda/m)$$ 每回合下降；（3）假设 $$\lambda$$ 不太大，权重下降会在权重降到 $$1/\sqrt{n}$$ 的时候保持住，其中 $$n$$ 是网络中权重的个数。用论述这些条件都已经满足本节给出的例子。

## 再看手写识别问题：代码
---
让我们实现本章讨论过的这些想法。我们将写出一个新的程序，`network2.py`，这是一个对第一章中开发的 `network.py` 的改进版本。如果你没有仔细看过 `network.py`，那你可能会需要重读前面关于这段代码的讨论。仅仅 $$74$$ 行代码，也很易懂。

和 `network.py` 一样，主要部分就是 `Network` 类了，我们用这个来表示神经网络。使用一个 `sizes` 的列表来对每个对应层进行初始化，默认使用交叉熵作为代价 `cost` 参数：
```python
class Network(object):

    def __init__(self, sizes, cost=CrossEntropyCost):
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.default_weight_initializer()
        self.cost=cost
```

`__init__` 方法的和 `network.py` 中一样，可以轻易弄懂。但是下面两行是新的，我们需要知道他们到底做了什么。

我们先看看 `default_weight_initializer` 方法，使用了我们新式改进后的初始化权重方法。如我们已经看到的，使用了均值为 $$0$$ 而标准差为 $$1/\sqrt{n}$$，$$n$$ 为对应的输入连接个数。我们使用均值为 $$0$$ 而标准差为 $$1$$ 的高斯分布来初始化偏差。下面是代码：
```python
def default_weight_initializer(self):
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x)/np.sqrt(x) 
                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]
```

为了理解这段代码，需要知道 `np` 就是进行线性代数运算的 Numpy 库。我们在程序的开头会 `import` Numpy。同样我们没有对第一层的神经元的偏差进行初始化。因为第一层其实是输入层，所以不需要引入任何的偏差。我们在 `network.py` 中做了完全一样的事情。

作为 `default_weight_initializer` 的补充，我们同样包含了一个 `large_weight_initializer` 方法。这个方法使用了第一章中的观点初始化了权重和偏差。代码也就仅仅是和`default_weight_initializer`差了一点点了：
```python
def large_weight_initializer(self):
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x) 
                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]
```

我将 `larger_weight_initializer` 方法包含进来的原因也就是使得跟第一章的结果更容易比较。我并没有考虑太多的推荐使用这个方法的实际情景。

初始化方法 `__init__` 中的第二个新的东西就是我们初始化了 `cost` 属性。为了理解这个工作的原理，让我们看一下用来表示交叉熵代价的类：
```python
class CrossEntropyCost(object):

    @staticmethod
    def fn(a, y):
        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))

    @staticmethod
    def delta(z, a, y):
        return (a-y)
```

让我们分解一下。第一个看到的是：即使使用的是交叉熵，数学上看，就是一个函数，这里我们用 Python 的类而不是 Python 函数实现了它。为什么这样做呢？答案就是代价函数在我们的网络中扮演了两种不同的角色。明显的角色就是代价是输出激活值 $$a$$ 和目标输出 $$y$$ 差距优劣的度量。这个角色通过 `CrossEntropyCost.fn` 方法来扮演。（注意，`np.nan_to_num` 调用确保了 Numpy 正确处理接近 $$0$$ 的对数值）但是代价函数其实还有另一个角色。回想第二章中运行反向传播算法时，我们需要计算网络输出误差，$$\delta^L$$。这种形式的输出误差依赖于代价函数的选择：不同的代价函数，输出误差的形式就不同。对于交叉熵函数，输出误差就如公式(66)所示：

![](http://upload-images.jianshu.io/upload_images/42741-f4261682261da621.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

所以，我们定义了第二个方法，`CrossEntropyCost.delta`，目的就是让网络知道如何进行输出误差的计算。然后我们将这两个组合在一个包含所有需要知道的有关代价函数信息的类中。

类似地，`network2.py` 还包含了一个表示二次代价函数的类。这个是用来和第一章的结果进行对比的，因为后面我们几乎都在使用交叉函数。代码如下。`QuadraticCost.fn` 方法是关于网络输出 $$a$$ 和目标输出 $$y$$ 的二次代价函数的直接计算结果。由 `QuadraticCost.delta` 返回的值就是二次代价函数的误差。
```python
class QuadraticCost(object):

    @staticmethod
    def fn(a, y):
        return 0.5*np.linalg.norm(a-y)**2

    @staticmethod
    def delta(z, a, y):
        return (a-y) * sigmoid_prime(z)
```
现在，我们理解了 `network2.py` 和 `network.py` 两个实现之间的主要差别。都是很简单的东西。还有一些更小的变动，下面我们会进行介绍，包含 L2 规范化的实现。在讲述规范化之前，我们看看 `network2.py` 完整的实现代码。你不需要太仔细地读遍这些代码，但是对整个结构尤其是文档中的内容的理解是非常重要的，这样，你就可以理解每段程序所做的工作。当然，你也可以随自己意愿去深入研究！如果你迷失了理解，那么请读读下面的讲解，然后再回到代码中。不多说了，给代码：
```python
"""network2.py
~~~~~~~~~~~~~~

An improved version of network.py, implementing the stochastic
gradient descent learning algorithm for a feedforward neural network.
Improvements include the addition of the cross-entropy cost function,
regularization, and better initialization of network weights.  Note
that I have focused on making the code simple, easily readable, and
easily modifiable.  It is not optimized, and omits many desirable
features.

"""

#### Libraries
# Standard library
import json
import random
import sys

# Third-party libraries
import numpy as np


#### Define the quadratic and cross-entropy cost functions

class QuadraticCost(object):

    @staticmethod
    def fn(a, y):
        """Return the cost associated with an output ``a`` and desired output
        ``y``.

        """
        return 0.5*np.linalg.norm(a-y)**2

    @staticmethod
    def delta(z, a, y):
        """Return the error delta from the output layer."""
        return (a-y) * sigmoid_prime(z)


class CrossEntropyCost(object):

    @staticmethod
    def fn(a, y):
        """Return the cost associated with an output ``a`` and desired output
        ``y``.  Note that np.nan_to_num is used to ensure numerical
        stability.  In particular, if both ``a`` and ``y`` have a 1.0
        in the same slot, then the expression (1-y)*np.log(1-a)
        returns nan.  The np.nan_to_num ensures that that is converted
        to the correct value (0.0).

        """
        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))

    @staticmethod
    def delta(z, a, y):
        """Return the error delta from the output layer.  Note that the
        parameter ``z`` is not used by the method.  It is included in
        the method's parameters in order to make the interface
        consistent with the delta method for other cost classes.

        """
        return (a-y)


#### Main Network class
class Network(object):

    def __init__(self, sizes, cost=CrossEntropyCost):
        """The list ``sizes`` contains the number of neurons in the respective
        layers of the network.  For example, if the list was [2, 3, 1]
        then it would be a three-layer network, with the first layer
        containing 2 neurons, the second layer 3 neurons, and the
        third layer 1 neuron.  The biases and weights for the network
        are initialized randomly, using
        ``self.default_weight_initializer`` (see docstring for that
        method).

        """
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.default_weight_initializer()
        self.cost=cost

    def default_weight_initializer(self):
        """Initialize each weight using a Gaussian distribution with mean 0
        and standard deviation 1 over the square root of the number of
        weights connecting to the same neuron.  Initialize the biases
        using a Gaussian distribution with mean 0 and standard
        deviation 1.

        Note that the first layer is assumed to be an input layer, and
        by convention we won't set any biases for those neurons, since
        biases are only ever used in computing the outputs from later
        layers.

        """
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x)/np.sqrt(x)
                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]

    def large_weight_initializer(self):
        """Initialize the weights using a Gaussian distribution with mean 0
        and standard deviation 1.  Initialize the biases using a
        Gaussian distribution with mean 0 and standard deviation 1.

        Note that the first layer is assumed to be an input layer, and
        by convention we won't set any biases for those neurons, since
        biases are only ever used in computing the outputs from later
        layers.

        This weight and bias initializer uses the same approach as in
        Chapter 1, and is included for purposes of comparison.  It
        will usually be better to use the default weight initializer
        instead.

        """
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x)
                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]

    def feedforward(self, a):
        """Return the output of the network if ``a`` is input."""
        for b, w in zip(self.biases, self.weights):
            a = sigmoid(np.dot(w, a)+b)
        return a

    def SGD(self, training_data, epochs, mini_batch_size, eta,
            lmbda = 0.0,
            evaluation_data=None,
            monitor_evaluation_cost=False,
            monitor_evaluation_accuracy=False,
            monitor_training_cost=False,
            monitor_training_accuracy=False):
        """Train the neural network using mini-batch stochastic gradient
        descent.  The ``training_data`` is a list of tuples ``(x, y)``
        representing the training inputs and the desired outputs.  The
        other non-optional parameters are self-explanatory, as is the
        regularization parameter ``lmbda``.  The method also accepts
        ``evaluation_data``, usually either the validation or test
        data.  We can monitor the cost and accuracy on either the
        evaluation data or the training data, by setting the
        appropriate flags.  The method returns a tuple containing four
        lists: the (per-epoch) costs on the evaluation data, the
        accuracies on the evaluation data, the costs on the training
        data, and the accuracies on the training data.  All values are
        evaluated at the end of each training epoch.  So, for example,
        if we train for 30 epochs, then the first element of the tuple
        will be a 30-element list containing the cost on the
        evaluation data at the end of each epoch. Note that the lists
        are empty if the corresponding flag is not set.

        """
        if evaluation_data: n_data = len(evaluation_data)
        n = len(training_data)
        evaluation_cost, evaluation_accuracy = [], []
        training_cost, training_accuracy = [], []
        for j in xrange(epochs):
            random.shuffle(training_data)
            mini_batches = [
                training_data[k:k+mini_batch_size]
                for k in xrange(0, n, mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(
                    mini_batch, eta, lmbda, len(training_data))
            print "Epoch %s training complete" % j
            if monitor_training_cost:
                cost = self.total_cost(training_data, lmbda)
                training_cost.append(cost)
                print "Cost on training data: {}".format(cost)
            if monitor_training_accuracy:
                accuracy = self.accuracy(training_data, convert=True)
                training_accuracy.append(accuracy)
                print "Accuracy on training data: {} / {}".format(
                    accuracy, n)
            if monitor_evaluation_cost:
                cost = self.total_cost(evaluation_data, lmbda, convert=True)
                evaluation_cost.append(cost)
                print "Cost on evaluation data: {}".format(cost)
            if monitor_evaluation_accuracy:
                accuracy = self.accuracy(evaluation_data)
                evaluation_accuracy.append(accuracy)
                print "Accuracy on evaluation data: {} / {}".format(
                    self.accuracy(evaluation_data), n_data)
            print
        return evaluation_cost, evaluation_accuracy, \
            training_cost, training_accuracy

    def update_mini_batch(self, mini_batch, eta, lmbda, n):
        """Update the network's weights and biases by applying gradient
        descent using backpropagation to a single mini batch.  The
        ``mini_batch`` is a list of tuples ``(x, y)``, ``eta`` is the
        learning rate, ``lmbda`` is the regularization parameter, and
        ``n`` is the total size of the training data set.

        """
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                       for b, nb in zip(self.biases, nabla_b)]

    def backprop(self, x, y):
        """Return a tuple ``(nabla_b, nabla_w)`` representing the
        gradient for the cost function C_x.  ``nabla_b`` and
        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar
        to ``self.biases`` and ``self.weights``."""
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # feedforward
        activation = x
        activations = [x] # list to store all the activations, layer by layer
        zs = [] # list to store all the z vectors, layer by layer
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation)+b
            zs.append(z)
            activation = sigmoid(z)
            activations.append(activation)
        # backward pass
        delta = (self.cost).delta(zs[-1], activations[-1], y)
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
        # Note that the variable l in the loop below is used a little
        # differently to the notation in Chapter 2 of the book.  Here,
        # l = 1 means the last layer of neurons, l = 2 is the
        # second-last layer, and so on.  It's a renumbering of the
        # scheme in the book, used here to take advantage of the fact
        # that Python can use negative indices in lists.
        for l in xrange(2, self.num_layers):
            z = zs[-l]
            sp = sigmoid_prime(z)
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
        return (nabla_b, nabla_w)

    def accuracy(self, data, convert=False):
        """Return the number of inputs in ``data`` for which the neural
        network outputs the correct result. The neural network's
        output is assumed to be the index of whichever neuron in the
        final layer has the highest activation.

        The flag ``convert`` should be set to False if the data set is
        validation or test data (the usual case), and to True if the
        data set is the training data. The need for this flag arises
        due to differences in the way the results ``y`` are
        represented in the different data sets.  In particular, it
        flags whether we need to convert between the different
        representations.  It may seem strange to use different
        representations for the different data sets.  Why not use the
        same representation for all three data sets?  It's done for
        efficiency reasons -- the program usually evaluates the cost
        on the training data and the accuracy on other data sets.
        These are different types of computations, and using different
        representations speeds things up.  More details on the
        representations can be found in
        mnist_loader.load_data_wrapper.

        """
        if convert:
            results = [(np.argmax(self.feedforward(x)), np.argmax(y))
                       for (x, y) in data]
        else:
            results = [(np.argmax(self.feedforward(x)), y)
                        for (x, y) in data]
        return sum(int(x == y) for (x, y) in results)

    def total_cost(self, data, lmbda, convert=False):
        """Return the total cost for the data set ``data``.  The flag
        ``convert`` should be set to False if the data set is the
        training data (the usual case), and to True if the data set is
        the validation or test data.  See comments on the similar (but
        reversed) convention for the ``accuracy`` method, above.
        """
        cost = 0.0
        for x, y in data:
            a = self.feedforward(x)
            if convert: y = vectorized_result(y)
            cost += self.cost.fn(a, y)/len(data)
        cost += 0.5*(lmbda/len(data))*sum(
            np.linalg.norm(w)**2 for w in self.weights)
        return cost

    def save(self, filename):
        """Save the neural network to the file ``filename``."""
        data = {"sizes": self.sizes,
                "weights": [w.tolist() for w in self.weights],
                "biases": [b.tolist() for b in self.biases],
                "cost": str(self.cost.__name__)}
        f = open(filename, "w")
        json.dump(data, f)
        f.close()

#### Loading a Network
def load(filename):
    """Load a neural network from the file ``filename``.  Returns an
    instance of Network.

    """
    f = open(filename, "r")
    data = json.load(f)
    f.close()
    cost = getattr(sys.modules[__name__], data["cost"])
    net = Network(data["sizes"], cost=cost)
    net.weights = [np.array(w) for w in data["weights"]]
    net.biases = [np.array(b) for b in data["biases"]]
    return net

#### Miscellaneous functions
def vectorized_result(j):
    """Return a 10-dimensional unit vector with a 1.0 in the j'th position
    and zeroes elsewhere.  This is used to convert a digit (0...9)
    into a corresponding desired output from the neural network.

    """
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e

def sigmoid(z):
    """The sigmoid function."""
    return 1.0/(1.0+np.exp(-z))

def sigmoid_prime(z):
    """Derivative of the sigmoid function."""
    return sigmoid(z)*(1-sigmoid(z))
```
有个更加有趣的变动就是在代码中增加了 L2 规范化。尽管这是一个主要的概念上的变动，在实现中其实相当简单。对大部分情况，仅仅需要传递参数 `lmbda` 到不同的方法中，主要是 `Network.SGD` 方法。实际上的工作就是一行代码的事在 `Network.update_mini_batch` 的倒数第四行。这就是我们改动梯度下降规则来进行权重下降的地方。尽管改动很小，但其对结果影响却很大！

其实这种情况在神经网络中实现一些新技术的常见现象。我们花费了近千字的篇幅来讨论规范化。概念的理解非常微妙困难。但是添加到程序中的时候却如此简单。精妙复杂的技术可以通过微小的代码改动就可以实现了。

另一个微小却重要的改动是随机梯度下降方法的几个标志位的增加。这些标志位让我们可以对在代价和准确度的监控变得可能。这些标志位默认是 `False` 的，但是在我们例子中，已经被置为 `True` 来监控 `Network` 的性能。另外，`network2.py` 中的 `Network.SGD` 方法返回了一个四元组来表示监控的结果。我们可以这样使用：
```python
>>> evaluation_cost, evaluation_accuracy, 
... training_cost, training_accuracy = net.SGD(training_data, 30, 10, 0.5,
... lmbda = 5.0,
... evaluation_data=validation_data,
... monitor_evaluation_accuracy=True,
... monitor_evaluation_cost=True,
... monitor_training_accuracy=True,
... monitor_training_cost=True)
```

所以，比如 `evaluation_cost` 将会是一个 $$30$$ 个元素的列表其中包含了每个回合在验证集合上的代价函数值。这种类型的信息在理解网络行为的过程中特别有用。比如，它可以用来画出展示网络随时间学习的状态。其实，这也是我在前面的章节中展示性能的方式。然而要注意的是如果任何标志位都没有设置的话，对应的元组中的元素就是空列表。

另一个增加项就是在 `Network.save` 方法中的代码，用来将 `Network` 对象保存在磁盘上，还有一个载回内存的函数。这两个方法都是使用 JSON 进行的，而非 Python 的 `pickle` 或者 `cPickle` 模块——这些通常是 Python 中常见的保存和装载对象的方法。使用 JSON 的原因是，假设在未来某天，我们想改变 `Network` 类来允许非 sigmoid 的神经元。对这个改变的实现，我们最可能是改变在 `Network.__init__` 方法中定义的属性。如果我们简单地 pickle 对象，会导致 `load` 函数出错。使用 JSON 进行序列化可以显式地让老的 Network 仍然能够 `load`。

其他也还有一些微小的变动。但是那些只是 `network.py` 的微调。结果就是把程序从 $$74$$ 行增长到了 $$152$$ 行。

### 问题
* 更改上面的代码来实现 L1 规范化，使用 L1 规范化使用 $$30$$ 个隐藏元的神经网络对 MNIST 数字进行分类。你能够找到一个规范化参数使得比无规范化效果更好么？
* 看看 `network.py` 中的 `Network.cost_derivative` 方法。这个方法是为二次代价函数写的。怎样修改可以用于交叉熵代价函数上？你能不能想到可能在交叉熵函数上遇到的问题？在 `network2.py` 中，我们已经去掉了 `Network.cost_derivative` 方法，将其集成进了 `CrossEntropyCost.delta` 方法中。请问，这样是如何解决你已经发现的问题的？

## 如何选择神经网络的超参数
---
直到现在，我们还没有解释对诸如学习率 $$\eta$$，规范化参数 $$\lambda$$ 等等超参数选择的方法。我只是给出那些效果很好的值而已。实践中，当你使用神经网络解决问题时，寻找好的超参数其实是很困难的一件事。例如，我们要解决 MNIST 问题，开始时对于选择什么样的超参数一无所知。假设，刚开始的实验中选择前面章节的参数都是运气较好。但在使用学习率 $$\eta=10.0$$ 而规范化参数 $$\lambda=1000.0$$。下面是我们的一个尝试：
```python
>>> import mnist_loader
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
>>> import network2
>>> net = network2.Network([784, 30, 10])
>>> net.SGD(training_data, 30, 10, 10.0, lmbda = 1000.0,
... evaluation_data=validation_data, monitor_evaluation_accuracy=True)
Epoch 0 training complete
Accuracy on evaluation data: 1030 / 10000

Epoch 1 training complete
Accuracy on evaluation data: 990 / 10000

Epoch 2 training complete
Accuracy on evaluation data: 1009 / 10000

...

Epoch 27 training complete
Accuracy on evaluation data: 1009 / 10000

Epoch 28 training complete
Accuracy on evaluation data: 983 / 10000

Epoch 29 training complete
Accuracy on evaluation data: 967 / 10000
```
我们分类准确度并不比随机选择更好。网络就像随机噪声产生器一样。

你可能会说，“这好办，降低学习率和规范化参数就好了。”不幸的是，你并不先验地知道这些就是需要调整的超参数。可能真正的问题出在 $$30$$ 个隐藏元中，本身就不能很有效，不管我们如何调整其他的超参数都没有作用的？可能我们真的需要至少 $$100$$ 个隐藏神经元？或者是 $$300$$ 个隐藏神经元？或者更多层的网络？或者不同输出编码方式？可能我们的网络一直在学习，只是学习的回合还不够？可能 minibatch 的太小了？可能我们需要切换成二次代价函数？可能我们需要尝试不同的权重初始化方法？等等。很容易就在超参数的选择中迷失了方向。如果你的网络规模很大，或者使用了很多的训练数据，这种情况就很令人失望了，因为一次训练可能就要几个小时甚至几天乃至几周，最终什么都没有获得。如果这种情况一直发生，就会打击你的自信心。可能你会怀疑神经网络是不是适合你所遇到的问题？可能就应该放弃这种尝试了？

本节，我会给出一些用于设定超参数的启发式想法。目的是帮你发展出一套工作流来确保很好地设置超参数。当然，我不会覆盖超参数优化的每个方法。那是太繁重的问题，而且也不会是一个能够完全解决的问题，也不存在一种通用的关于正确策略的共同认知。总是会有一些新的技巧可以帮助你提高一点性能。但是本节的启发式想法能帮你开个好头。

**宽的策略**：在使用神经网络来解决新的问题时，一个挑战就是获得**任何**一种非寻常的学习，也就是说，达到比随机的情况更好的结果。这个实际上会很困难，尤其是遇到一种新类型的问题时。让我们看看有哪些策略可以在面临这类困难时候尝试。

假设，我们第一次遇到 MNIST 分类问题。刚开始，你很有激情，但是当第一个神经网络完全失效时，你会就得有些沮丧。此时就可以将问题简化。丢开训练和验证集合中的那些除了 $$0$$ 和 $$1$$ 的那些图像。然后试着训练一个网络来区分 $$0$$ 和 $$1$$。不仅仅问题比 $$10$$ 个分类的情况简化了，同样也会减少 80% 的训练数据，这样就给出了 $$5$$ 倍的加速。这样可以保证更快的实验，也能给予你关于如何构建好的网络更快的洞察。

你通过简化网络来加速实验进行更有意义的学习。如果你相信 $$[784, 10]$$ 的网络更可能比随机更加好的分类效果，那么就从这个网络开始实验。这会比训练一个 $$[784, 30 ,10]$$ 的网络更快，你可以进一步尝试后一个。

你可以通过提高监控的频率来在试验中获得另一个加速了。在 `network2.py` 中，我们在每个训练的回合的最后进行监控。每回合 $$50,000$$，在接受到网络学习状况的反馈前需要等上一会儿——在我的笔记本上训练 $$[784, 30, 10]$$ 网络基本上每回合 $$10$$ 秒。当然，$$10$$ 秒并不太长，不过你希望尝试几十种超参数就很麻烦了，如果你想再尝试更多地选择，那就相当棘手了。我们可以通过更加频繁地监控验证准确度来获得反馈，比如说在每 $$1,000$$ 次训练图像后。而且，与其使用整个 $$10,000$$ 幅图像的验证集来监控性能，我们可以使用 $$100$$ 幅图像来进行验证。真正重要的是网络看到足够多的图像来做真正的学习，获得足够优秀的估计性能。当然，我们的程序 `network2.py` 并没有做这样的监控。但是作为一个凑合的能够获得类似效果的方案，我们将训练数据减少到前 $$1,000$$ 幅 MNIST 训练图像。让我们尝试一下，看看结果。（为了让代码更加简单，我并没有取仅仅是 0 和 1 的图像。当然，那样也是很容易就可以实现）。
```python
>>> net = network2.Network([784, 10])
>>> net.SGD(training_data[:1000], 30, 10, 10.0, lmbda = 1000.0, \
... evaluation_data=validation_data[:100], \
... monitor_evaluation_accuracy=True)
Epoch 0 training complete
Accuracy on evaluation data: 10 / 100

Epoch 1 training complete
Accuracy on evaluation data: 10 / 100

Epoch 2 training complete
Accuracy on evaluation data: 10 / 100
...
```
我们仍然获得完全的噪声！但是有一个进步：现在我们每一秒钟可以得到反馈，而不是之前每 10 秒钟才可以。这意味着你可以更加快速地实验其他的超参数，或者甚至近同步地进行不同参数的组合的评比。

在上面的例子中，我设置 $$\lambda=1000.0$$，跟我们之前一样。但是因为这里改变了训练样本的个数，我们必须对 $$\lambda$$ 进行调整以保证权重下降的同步性。这意味着改变 $$\lambda = 20.0$$。如果我们这样设置，则有：
```python
>>> net = network2.Network([784, 10])
>>> net.SGD(training_data[:1000], 30, 10, 10.0, lmbda = 20.0, \
... evaluation_data=validation_data[:100], \
... monitor_evaluation_accuracy=True)
Epoch 0 training complete
Accuracy on evaluation data: 12 / 100

Epoch 1 training complete
Accuracy on evaluation data: 14 / 100

Epoch 2 training complete
Accuracy on evaluation data: 25 / 100

Epoch 3 training complete
Accuracy on evaluation data: 18 / 100
...
```

哦也！现在有了信号了。不是非常糟糕的信号，却真是一个信号。我们可以基于这点，来改变超参数从而获得更多的提升。可能我们猜测学习率需要增加（你可以能会发现，这只是一个不大好的猜测，原因后面会讲，但是相信我）所以为了测试我们的猜测就将 $$\eta$$ 调整至 $$100.0$$:
```python
>>> net = network2.Network([784, 10])
>>> net.SGD(training_data[:1000], 30, 10, 100.0, lmbda = 20.0, \
... evaluation_data=validation_data[:100], \
... monitor_evaluation_accuracy=True)
Epoch 0 training complete
Accuracy on evaluation data: 10 / 100

Epoch 1 training complete
Accuracy on evaluation data: 10 / 100

Epoch 2 training complete
Accuracy on evaluation data: 10 / 100

Epoch 3 training complete
Accuracy on evaluation data: 10 / 100

...
```
这并不好！告诉我们之前的猜测是错误的，问题并不是学习率太低了。所以，我们试着将 $$\eta$$ 将至 $$\eta=1.0$$：
```python
>>> net = network2.Network([784, 10])
>>> net.SGD(training_data[:1000], 30, 10, 1.0, lmbda = 20.0, \
... evaluation_data=validation_data[:100], \
... monitor_evaluation_accuracy=True)
Epoch 0 training complete
Accuracy on evaluation data: 62 / 100

Epoch 1 training complete
Accuracy on evaluation data: 42 / 100

Epoch 2 training complete
Accuracy on evaluation data: 43 / 100

Epoch 3 training complete
Accuracy on evaluation data: 61 / 100

...
```
这样好点了！所以我们可以继续，逐个调整每个超参数，慢慢提升性能。一旦我们找到一种提升性能的 $$\eta$$ 值，我们就可以尝试寻找好的值。然后按照一个更加复杂的网络架构进行实验，假设是一个有 $$10$$ 个隐藏元的网络。然后继续调整 $$\eta$$ 和 $$\lambda$$。接着调整成 $$20$$ 个隐藏元。然后将其他的超参数调整再调整。如此进行，在每一步使用我们 hold out 验证数据集来评价性能，使用这些度量来找到越来越好的超参数。当我们这么做的时候，一般都需要花费更多时间来发现由于超参数改变带来的影响，这样就可以一步步减少监控的频率。

所有这些作为一种宽泛的策略看起来很有前途。然而，我想要回到寻找超参数的原点。实际上，即使是上面的讨论也传达出过于乐观的观点。实际上，很容易会遇到神经网络学习不到任何知识的情况。你可能要花费若干天在调整参数上，仍然没有进展。所以我想要再重申一下在前期你应该从实验中尽可能早的获得快速反馈。直觉上看，这看起来简化问题和架构仅仅会降低你的效率。实际上，这样能够将进度加快，因为你能够更快地找到传达出有意义的信号的网络。一旦你获得这些信号，你可以尝尝通过微调超参数获得快速的性能提升。这和人生中很多情况一样——万事开头难。

好了，上面就是宽泛的策略。现在我们看看一些具体的设置超参数的推荐。我会聚焦在学习率 $$\eta$$，L2 规范化参数 $$\lambda$$，和 minibatch 大小。然而，很多的观点同样可以应用在其他的超参数的选择上，包括一些关于网络架构的、其他类型的规范化和一些本书后面遇到的如 momentum co-efficient 这样的超参数。

**学习率**：假设我们运行了三个不同学习率（$$\eta=0.025$$、$$\eta=0.25$$、$$\eta=2.5$$）的 MNIST 网络。我们会像前面介绍的实验那样设置其他的超参数，进行 $$30$$ 回合，minibatch 大小为 $$10$$，然后 $$\lambda = 5.0$$。我们同样会使用整个 $$50,000$$ 幅训练图像。下面是一副展示了训练代价的变化情况的图：

![](http://upload-images.jianshu.io/upload_images/42741-bd87b721fb6d54bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用 $$\eta=0.025$$，代价函数平滑下降到最后的回合。使用 $$\eta=0.25$$，代价刚开始下降，在大约 $$20$$ 回合后接近饱和状态，后面就是微小的震荡和随机抖动。最终使用 $$\eta=2.5$$ 代价从始至终都震荡得非常明显。为了理解震荡的原因，回想一下随机梯度下降其实是期望我们能够逐渐地抵达代价函数的谷底的，

![](http://upload-images.jianshu.io/upload_images/42741-a931da4bbd314dfc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

然而，如果 $$\eta$$ 太大的话，步长也会变大可能会使得算法在接近最小值时候又越过了谷底。这在 $$\eta=2.5$$ 时非常可能发生。当我们选择 $$\eta=0.25$$ 时，初始几步将我们带到了谷底附近，但一旦到达了谷底，又很容易跨越过去。而在我们选择 $$\eta=0.025$$ 时，在前 $$30$$ 回合的训练中不再受到这个情况的影响。当然，选择太小的学习率，也会带来另一个问题——随机梯度下降算法变慢了。一种更加好的策略其实是，在开始时使用 $$\eta=0.25$$，随着越来越接近谷底，就换成 $$\eta=0.025$$。这种可变学习率的方法我们后面会介绍。现在，我们就聚焦在找出一个单独的好的学习率的选择，$$\eta$$。

所以，有了这样的想法，我们可以如下设置 $$\eta$$。首先，我们选择在训练数据上的代价立即开始下降而非震荡或者增加时作为 $$\eta$$ 的阈值的估计。这个估计并不需要太过精确。你可以估计这个值的量级，比如说从 $$\eta=0.01$$ 开始。如果代价在训练的前面若干回合开始下降，你就可以逐步地尝试 $$\eta=0.1, 1.0,...$$，直到你找到一个 $$\eta$$ 的值使得在开始若干回合代价就开始震荡或者增加。相反，如果代价在 $$\eta=0.01$$ 时就开始震荡或者增加，那就尝试 $$\eta=0.001, 0.0001,...$$ 直到你找到代价在开始回合就下降的设定。按照这样的方法，我们可以掌握学习率的阈值的量级的估计。你可以选择性地优化估计，选择那些最大的 $$\eta$$，比方说 $$\eta=0.5$$ 或者 $$\eta=0.2$$（这里也不需要过于精确）。

显然，$$\eta$$ 实际值不应该比阈值大。实际上，如果 $$\eta$$ 的值重复使用很多回合的话，你更应该使用稍微小一点的值，例如，阈值的一半这样的选择。这样的选择能够允许你训练更多的回合，不会减慢学习的速度。

在 MNIST 数据中，使用这样的策略会给出一个关于学习率 $$\eta$$ 的一个量级的估计，大概是 $$0.1$$。在一些改良后，我们得到了阈值 $$\eta=0.5$$。所以，我们按照刚刚的取一半的策略就确定了学习率为 $$\eta=0.25$$。实际上，我发现使用 $$\eta=0.5$$ 在 $$30$$ 回合内表现是很好的，所以选择更低的学习率，也没有什么问题。

这看起来相当直接。然而，使用训练代价函数来选择 $$\eta$$ 看起来和我们之前提到的通过验证集来确定超参数的观点有点矛盾。实际上，我们会使用验证准确度来选择规范化超参数，minibatch 大小，和层数及隐藏元个数这些网络参数，等等。为何对学习率要用不同的方法呢？坦白地说，这些选择其实是我个人美学偏好，个人习惯罢了。原因就是其他的超参数倾向于提升最终的测试集上的分类准确度，所以将他们通过验证准确度来选择更合理一些。然而，学习率仅仅是偶然地影响最终的分类准确度的。学习率主要的目的是控制梯度下降的步长，监控训练代价是最好的检测步长过大的方法。所以，这其实就是个人的偏好。在学习的前期，如果验证准确度提升，训练代价通常都在下降。所以在实践中使用那种衡量方式并不会对判断的影响太大。

**使用 Early stopping 来确定训练的回合数**：正如我们在本章前面讨论的那样，Early stopping 表示在每个回合的最后，我们都要计算验证集上的分类准确度。当准确度不再提升，就终止它。这让选择回合数变得很简单。特别地，也意味着我们不再需要担心显式地掌握回合数和其他超参数的关联。而且，这个过程还是自动的。另外，Early stopping 也能够帮助我们避免过匹配。尽管在实验前期不采用 Early stopping，这样可以看到任何过匹配的信号，使用这些来选择规范化方法，但 early stopping 仍然是一件很棒的事。

我们需要再明确一下什么叫做分类准确度不再提升，这样方可实现 Early stopping。正如我们已经看到的，分类准确度在整体趋势下降的时候仍旧会抖动或者震荡。如果我们在准确度刚开始下降的时候就停止，那么肯定会错过更好的选择。一种不错的解决方案是如果分类准确度在一段时间内不再提升的时候终止。例如，我们要解决 MNIST 问题。如果分类准确度在近 $$10$$ 个回合都没有提升的时候，我们将其终止。这样不仅可以确保我们不会终止得过快，也能够使我们不要一直干等直到出现提升。

这种 $$10$$ 回合不提升就终止的规则很适合 MNIST 问题的一开始的探索。然而，网络有时候会在很长时间内于一个特定的分类准确度附近形成平缓的局面，然后才会有提升。如果你尝试获得相当好的性能，这个规则可能就会太过激进了——停止得太草率。所以，我建议在你更加深入地理解网络训练的方式时，仅仅在初始阶段使用 $$10$$ 回合不提升规则，然后逐步地选择更久的回合，比如说：$$20$$ 回合不提升就终止，$$20$$ 回合不提升就终止，以此类推。当然，这就引入了一种新的需要优化的超参数！实践中，其实比较容易设置这个超参数来获得相当好的结果。类似地，对不同于 MNIST 的问题，$$10$$ 回合不提升就终止的规则会太多激进或者太多保守，这都取决于问题的本身特质。然而，进行一些小的实验，发现好的提前终止的策略还是非常简单的。

我们还没有使用提前终止在我们的 MNIST 实验中。原因是我们已经比较了不同的学习观点。这样的比较其实比较适合使用同样的训练回合。但是，在 `network2.py` 中实现提前终止还是很有价值的：

### 问题
* 修改 `network2.py` 来实现提前终止，并让 $$n$$ 回合不提升终止策略中的 $$n$$ 称为可以设置的参数。
* 你能够想出不同于 $$n$$ 回合不提升终止策略的其他提前终止策略么？理想中，规则应该能够获得更高的验证准确度而不需要训练太久。将你的想法实现在 `network2.py` 中，运行这些实验和 $$10$$ 回合不提升终止策略比较对应的验证准确度和训练的回合数。

**学习率调整**：我们一直都将学习率设置为常量。但是，通常采用可变的学习率更加有效。在学习的前期，权重可能非常糟糕。所以最好是使用一个较大的学习率让权重变化得更快。越往后，我们可以降低学习率，这样可以作出更加精良的调整。

我们要如何设置学习率呢？其实有很多方法。一种自然的观点是使用提前终止的想法。就是保持学习率为一个常量知道验证准确度开始变差。然后按照某个量下降学习率，比如说按照 $$10$$ 或者 $$2$$。我们重复此过程若干次，知道学习率是初始值的 $$1/1024$$（或者$$1/1000$$）。那时就终止。

可变学习率可以提升性能，但是也会产生大量可能的选择。这些选择会让人头疼——你可能需要花费很多精力才能优化学习规则。对刚开始实验，我建议使用单一的常量作为学习率的选择。这会给你一个比较好的近似。后面，如果你想获得更好的性能，值得按照某种规则进行实验，根据我已经给出的资料。
> A readable recent paper which demonstrates the benefits of variable learning rates in attacking MNIST is [Deep, Big, Simple Neural Nets Excel on Handwritten Digit Recognition](http://arxiv.org/abs/1003.0358), by Dan Claudiu Cireșan, Ueli Meier, Luca Maria Gambardella, and Jürgen Schmidhuber (2010).

### 练习
* 更改 `network2.py` 实现学习规则：每次验证准确度满足满足$$10$$ 回合不提升终止策略时改变学习率；当学习率降到初始值的 $$1/128$$ 时终止。

**规范化参数**：我建议，开始时不包含规范化（$$\lambdas=0.0$$），确定 $$\eta$$ 的值。使用确定出来的 $$\eta$$，我们可以使用验证数据来选择好的 $$\lambda$$。从尝试 $$\lambda=1.0$$ 开始，然后根据验证集上的性能按照因子 $$10$$增加或减少其值。一旦我已经找到一个好的量级，你可以改进 $$\lambda$$ 的值。这里搞定后，你就可以返回再重新优化 $$\eta$$。

### 练习
* 使用梯度下降来尝试学习好的超参数的值其实很受期待。你可以想像关于使用梯度下降来确定 $$\lambda$$ 的障碍么？你能够想象关于使用梯度下降来确定 $$\eta$$ 的障碍么？

**在本书前面，我是如何选择超参数的**：如果你使用本节给出的推荐策略，你会发现你自己找到的 $$\eta$$ 和 $$\lambda$$ 不总是和我给出的一致。原因自傲与，本书有一些限制，有时候会使得优化超参数变得不现实。想想我们已经做过的使用不同观点学习的对比，比如说，比较二次代价函数和交叉熵代价函数，比较权重初始化的新旧方法，使不使用规范化，等等。为了使这些比较有意义，我通常会将参数在这些方法上保持不变（或者进行合适的尺度调整）。当然，同样超参数对不同的学习观点都是最优的也没有理论保证，所以我用的那些超参数常常是折衷的选择。

相较于这样的折衷，其实我本可以尝试优化每个单一的观点的超参数选择。理论上，这可能是更好更公平的方式，因为那样的话我们可以看到每个观点的最优性能。但是，我们现在依照目前的规范进行了众多的比较，实践上，我觉得要做到需要过多的计算资源了。这也是我使用折衷方式来采用尽可能好（却不一定最优）的超参数选择。

**minibatch 大小**：我们应该如何设置 minibatch 的大小？为了回答这个问题，让我们先假设正在进行在线学习，也就是说使用大小为 $$1$$ 的minibatch。

一个关于在线学习的担忧是使用只有一个样本的 minibatch 会带来关于梯度的错误估计。实际上，误差并不会真的产生这个问题。原因在于单一的梯度估计不需要绝对精确。我们需要的是确保代价函数保持下降的足够精确的估计。就像你现在要去北极点，但是只有一个不大精确的（差个 $$10-20$$ 度）指南针。如果你不再频繁地检查指南针，指南针会在平均状况下给出正确的方向，所以最后你也能抵达北极点。

基于这个观点，这看起来好像我们需要使用在线学习。实际上，情况会变得更加复杂。在[上一章的问题中](http://neuralnetworksanddeeplearning.com/chap2.html#backprop_over_minibatch) 我指出我们可以使用矩阵技术来对所有在 minibatch 中的样本同时计算梯度更新，而不是进行循环。所以，取决于硬件和线性代数库的实现细节，这会比循环方式进行梯度更新快好多。也许是 $$50$$ 和 $$100$$ 倍的差别。

现在，看起来这对我们帮助不大。我们使用 $$100$$ 的minibatch 的学习规则如下;

![](http://upload-images.jianshu.io/upload_images/42741-0da5e4d4158d7584.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里是对 minibatch 中所有训练样本求和。而在线学习是

![](http://upload-images.jianshu.io/upload_images/42741-e4cf80fa0ba47bd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

即使它仅仅是 $$50$$ 倍的时间，结果仍然比直接在线学习更好，因为我们在线学习更新得太过频繁了。假设，在 minibatch 下，我们将学习率扩大了 $$100$$ 倍，更新规则就是

![](http://upload-images.jianshu.io/upload_images/42741-cc1e54ceb80dea12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这看起来项做了 $$100$$ 次独立的在线学习。但是仅仅比在线学习花费了 $$50$$ 倍的时间。当然，其实不是同样的 100 次在线学习，因为 minibatch 中 $$\nabla C_x$$ 是都对同样的权重进行衡量的，而在线学习中是累加的学习。使用更大的 minibatch 看起来还是显著地能够进行训练加速的。

所以，选择最好的 minibatch 大小也是一种折衷。太小了，你不会用上很好的矩阵库的快速计算。太大，你是不能够足够频繁地更新权重的。你所需要的是选择一个折衷的值，可以最大化学习的速度。幸运的是，minibatch 大小的选择其实是相对独立的一个超参数（网络整体架构外的参数），所以你不需要优化那些参数来寻找好的 minibatch 大小。因此，可以选择的方式就是使用某些可以接受的值（不需要是最优的）作为其他参数的选择，然后进行不同 minibatch 大小的尝试，像上面那样调整 $$\eta$$。画出验证准确度的值随时间（非回合）变化的图，选择哪个得到最快性能的提升的 minibatch 大小。得到了 minibatch 大小，也就可以对其他的超参数进行优化了。

当然，你也发现了，我这里并没有做到这么多。实际上，我们的实现并没有使用到 minibatch 更新快速方法。就是简单使用了 minibatch 大小为 $$10$$。所以，我们其实可以通过降低 minibatch 大小来进行提速。我也没有这样做，因为我希望展示 minibatch 大于 $$1$$ 的使用，也因为我实践经验表示提升效果其实不明显。在实践中，我们大多数情况肯定是要实现更快的 minibatch 更新策略，然后花费时间精力来优化 minibatch 大小，来达到总体的速度提升。

**自动技术**：我已经给出很多在手动进行超参数优化时的启发式规则。手动选择当然是种理解网络行为的方法。不过，现实是，很多工作已经使用自动化过程进行。通常的技术就是**网格搜索**（grid search），可以系统化地对超参数的参数空间的网格进行搜索。网格搜索的成就和限制（易于实现的变体）在 James Bergstra 和 Yoshua Bengio $$2012$$ 年的[论文](http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf)中已经给出了综述。很多更加精细的方法也被大家提出来了。我这里不会给出介绍，但是想指出 2012 年使用贝叶斯观点自动优化超参数的论文。[代码可以获得](https://github.com/jaberg/hyperopt)，也已经被其他的研究人员使用了。

**总结**：跟随上面的经验并不能帮助你的网络给出绝对最优的结果。但是很可能给你一个好的开始和一个改进的基础。特别地，我已经非常独立地讨论了超参数的选择。实践中，超参数之间存在着很多关系。你可能使用 $$\eta$$ 进行试验，发现效果不错，然后去优化 $$\lambda$$，发现这里又对 $$\eta$$ 混在一起了。在实践中，一般是来回往复进行的，最终逐步地选择到好的值。总之，启发式规则其实都是经验，不是金规玉律。你应该注意那些没有效果的尝试的信号，然后乐于尝试更多试验。特别地，这意味着需要更加细致地监控神经网络行为，特别是验证集上的准确度。

选择超参数的难度由于如何选择超参数的方法太繁多（分布在太多的研究论文，软件程序和仅仅在一些研究人员的大脑中）变得更加困难。很多很多的论文给出了（有时候矛盾的）建议。然而，还有一些特别有用的论文对这些繁杂的技术进行了梳理和总结。Yoshua Bengio 在 $$2012$$ 年的论文中给出了一些实践上关于训练神经网络用到的反向传播和梯度下降的技术的推荐策略。Bengio 对很多问题的讨论比我这里更加细致，其中还包含如何进行系统化的超参数搜索。另一篇文章是 $$1998$$ 年的 Yann LeCun、Léon Bottou、Genevieve Orr 和 Klaus-Robert Müller 的。这些论文搜集在 2012年的一本书中，这本书介绍了很多训练神经网络的常用技巧。这本书挺贵的，但很多的内容其实已经被作者共享在网络上了，也许在搜搜引擎上能够找到一些。

在你读这些文章时，特别是进行试验时，会更加清楚的是超参数优化就不是一个已经被完全解决的问题。总有一些技巧能够尝试着来提升性能。有句关于作家的谚语是：“书从来不会完结，只会被丢弃。”这点在神经网络优化上也是一样的：超参数的空间太大了，所以人们无法真的完成优化，只能将问题丢给后人。所以你的目标应是发展出一个工作流来确保自己快速地进行参数优化，这样可以留有足够的灵活性空间来尝试对重要的参数进行更加细节的优化。

设定超参数的挑战让一些人抱怨神经网络相比较其他的机器学习算法需要大量的工作进行参数选择。我也听到很多不同的版本：“的确，参数完美的神经网络可能会在这问题上获得最优的性能。但是，我可以尝试一下随机森林（或者 SVM 或者……这里脑补自己偏爱的技术）也能够工作的。我没有时间搞清楚那个最好的神经网络。” 当然，从一个实践者角度，肯定是应用更加容易的技术。这在你刚开始处理某个问题时尤其如此，因为那时候，你都不确定一个机器学习算法能够解决那个问题。但是，如果获得最优的性能是最重要的目标的话，你就可能需要尝试更加复杂精妙的知识的方法了。如果机器学习总是简单的话那是太好不过了，但也没有一个应当的理由说机器学习非得这么简单。

## 其他技术
---
本章中讲述的每个技术都是很值得学习的，但是不仅仅是由于那些我提到的愿意。更重要的其实是让你自己熟悉在神经网络中出现的问题以及解决这些问题所进行分析的方式。所以，我们现在已经学习了如何思考神经网络。本章后面部分，我会简要地介绍一系列其他技术。这些介绍相比之前会更加粗浅，不过也会传达出关于神经网络中多样化的技术的精神。

## 随机梯度下降的变种
通过反向传播进行的随机梯度下降已经在 MNIST 数字分类问题上有了很好的表现。然而，还有很多其他的观点来优化代价函数，有时候，这些方法能够带来比 minibatch 随机梯度下降更好的效果。本节，我会介绍两种观点，Hessian 和 momentum 技术。

**Hessian 技术**：为了更好地讨论这个技术，我们先把神经网络放在一边。相反，我直接思考最小化代价函数 $$C$$ 的抽象问题，其中 $$C$$ 是多个参数的函数，$$w=w_1,w_2,...$$，所以 $$C=C(w)$$。借助于泰勒展开式，代价函数可以在点 $$w$$ 处被近似为：

![](http://upload-images.jianshu.io/upload_images/42741-7fe2a9174d6f1510.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以将其压缩为：

![](http://upload-images.jianshu.io/upload_images/42741-e66e86fff3ac6570.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 $$\nabla C$$ 是通常的梯度向量，$$H$$ 就是矩阵形式的 Hessian 矩阵，其中 $$jk$$-th 项就是 $$\partial^2 C/\partial w_j\partial w_k$$。假设我们通过丢弃更高阶的项来近似 $$C$$，

![](http://upload-images.jianshu.io/upload_images/42741-9b9b89fd5dd6c6d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用微积分，我们可证明右式表达式可以进行最小化，选择：

![Paste_Image.png](http://upload-images.jianshu.io/upload_images/42741-f68cc3337ad87e85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

根据(105)是代价函数的比较好的近似表达式，我们期望从点 $$w$$ 移动到 $$w+\Delta w = w - H^{-1}\nabla C$$ 可以显著地降低代价函数的值。这就给出了一种优化代价函数的可能的算法：
* 选择开始点，$$w$$
* 更新 $$w$$ 到新点 $$w' = w - H_{-1}\nabla C$$，其中 Hessian $$H$$ 和 $$\nabla C$$ 在 $$w$$ 处计算出来的
* 更新  $$w'$$ 到新点 $$w'' = w' - H'^{-1}\nabla' C$$，其中 Hessian $$H'$$ 和 $$\nabla' C$$ 在 $$w'$$ 处计算出来的
* ...

实际应用中，(105)是唯一的近似，并且选择更小的 step 会更好。我们通过重复地使用改变量 $$\Delta w = -\etaH^{-1} \nabla C$$ 来 改变 $$w$$，其中 $$\eta$$ 就是学习率。

### 有关神经网络的故事
> **问题**：你怎么看那些全部由实验效果支撑（而非数学保证）的使用和研究机器学习技术呢？同样，在哪些场景中，你已经注意到这些技术失效了？

> **答案**：你需要认识到，我们的理论工具的缺乏。有时候，我们有很好的关于某些特定的技术应该可行的数学直觉。有时候我们的直觉最终发现是错误的。…… 这个问题其实是：我的方法在这个特定的问题的工作得多好，还有方法表现好的那些问题的范围有多大。
- *[Question and answer](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/chivdv7)* by Yann LeCun

曾经我参加量子力学基础的会议时，我注意到让我最好奇的口头表达：在报告结束时，听众的问题通常是以“我对你的观点很赞同，但是...”开始。量子力学基础不是我的擅长领域，我注意到这种类型的质疑，因为在其他的科学会议上，我很少（或者说，从未）听到这种同情。那时候，我思考了这类问题存在的原因，实际上是因为这个领域中很少有重大的进展，人们都是停在原地。后来，我意识到，这个观念相当的尖刻。发言人正在尝试解决一些人们所遇到的一些最难的问题。进展当然会非常缓慢！但是，听听人们目前正在思考的方式也是非常有价值的，即使这些尝试不一定会有无可置疑的新进展。

你可能会注意到类似于“我对你的观点很赞同，但是...”的话语。为了解释我们已经看到的情况，我通常会使用“启发式地，...”或者“粗略地讲，...”，然后接上解释某个现象或者其他问题的故事。这些故事是可信的，但是实验性的证据常常是不够充分的。如果你通读研究文献，你会发现在神经网络研究中很多类似的表达，基本上都是没有太过充分的支撑证据的。所以我们应该怎样看待这样的故事呢？

在科学的很多分支——尤其是那些解决相当简单现象的领域——很容易会得到一些关于很一般的假说的非常扎实非常可靠的证据。但是在神经网络中，存在大量的参数和超参数及其间极其复杂的交互。在这样复杂系统中，构建出可靠的一般的论断就尤其困难。在完全一般性上理解神经网络实际上，和量子力学基础一样，都是对人类思维极限的挑战。实际上，我们通常是和一些一般的理论的具体的实例在打交道——找到正面或者反面的证据。所以，这些理论在有新的证据出现时，也需要进行调整甚至丢弃。

对这种情况的一种观点是——任何启发式的关于神经网络的论点会带来一个挑战。例如，考虑[之前我引用的语句](http://neuralnetworksanddeeplearning.com/chap3.html#dropout_explanation) ，解释 dropout 工作的原因：“这个技术减少了复杂的神经元之间的互适应，因为一个神经元不能够依赖于特定其他神经元的存在。因此，这个就强制性地让我们学习更加健壮的在很多不同的神经元的随机子集的交集中起到作用的那些特征。”这是一个丰富而又争议的假说，我们可以根据这个观点发展出一系列的研究项目，搞清楚哪些部分真的，哪些是假的，那个需要变化和改良。实际上，有一小部分研究人员正在调查 dropout（和其他变体）试着理解其工作的机制，还有 dropout 的极限所在。所以，这些研究也跟随着那些我们已经讨论过的启发式想法。每个启发式想法不仅仅是一个（潜在的）解释，同样也是一种更加细化地调查和理解的挑战。

当然，对某个单独的人去研究所有这些启发式想法其实在时间上是不允许的。需要神经网络的研究群体花费数十年（或者更多）来发展出一个相当强大，基于证据的关于神经网络工作的原理的理论。那么这是不是就意味着我们应当因为它的不严格和无法充分地证明而放弃启发式规则么？不！实际上，我们需要这样的启发式想法来启迪和指导我们的思考。这有点像大航海时代：早期的探险家在一种重要的指导方式都有错误的前提下有时候都进行了探索（并作出了新的发现）。后来，这些错误在我们对地理知识的清晰后而被纠正过来。当你对某件事理解不深时——就像探险家对地理的理解和我们现在对神经网络的理解——忽略一些相对严格的纠正每一步思考而胆大地探索若干问题显得更加重要。所以你应该将这些故事看成是一种关于我们如何思考神经网络的有用的指导，同时保留关于这些想法的能力极限的合理的关注，并细致地跟踪对任何一个推理的证据的强弱。换言之，我们需要很好的故事来不断地激励和启发自己去勇敢地探索，同时使用严格的深刻的调查来发现真理。